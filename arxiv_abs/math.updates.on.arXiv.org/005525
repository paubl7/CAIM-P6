In \cite{Stojnicclupint19,Stojnicclupcmpl19,Stojnicclupplt19} we introduced CLuP, a \bl{\textbf{Random
Duality Theory (RDT)}} based algorithmic mechanism that can be used for solving hard optimization
problems. Due to their introductory nature, \cite{Stojnicclupint19,Stojnicclupcmpl19,Stojnicclupplt19}
discuss the most fundamental CLuP concepts. On the other hand, in our companion paper \cite{Stojniccluplargesc20}
we started the story of going into a bit deeper details that relate to many of other remarkable CLuP
properties with some of them reaching well beyond the basic fundamentals. Namely, \cite{Stojniccluplargesc20}
discusses how a somewhat silent RDT feature (its algorithmic power) can be utilized to ensure that
CLuP can be run on very large problem instances as well. In particular, applying CLuP to the famous
MIMO ML detection problem we showed in \cite{Stojniccluplargesc20} that its a large scale variant,
$\text{CLuP}^{r_0}$, can handle with ease problems with \textbf{\emph{several thousands}}
of unknowns with theoretically minimal complexity per iteration (only a single matrix-vector
multiplication suffices). In this paper we revisit MIMO ML detection and discuss another remarkable
phenomenon that emerges within the CLuP structure, namely the so-called \bl{\textbf{\emph{rephasing}}}.
As MIMO ML enters the so-called low $\alpha$ regime (fat system matrix with ratio of the number of
rows and columns, $\alpha$, going well below $1$) it becomes increasingly difficult even for the
basic standard CLuP to handle it. However, the discovery of the rephasing ensures that CLuP remains
on track and preserves its ability to achieve the ML performance. To demonstrate the power of the
rephasing we also conducted quite a few numerical experiments, compared the results we obtained
through them to the theoretical predictions, and observed an excellent agreement. 