Representations of the world environment play a crucial role in machine intelligence. It is often
inefficient to conduct reasoning and inference directly in the space of raw sensory representations,
such as pixel values of images. Representation learning allows us to automatically discover suitable
representations from raw sensory data. For example, given raw sensory data, a multilayer perceptron
learns nonlinear representations at its hidden layers, which are subsequently used for classification
(or regression) at its output layer. This happens implicitly during training through minimizing
a supervised or unsupervised loss. In this paper, we study the dynamics of such implicit nonlinear
representation learning. We identify a pair of a new assumption and a novel condition, called the
common model structure assumption and the data-architecture alignment condition. Under the common
model structure assumption, the data-architecture alignment condition is shown to be sufficient
for the global convergence and necessary for the global optimality. Our results provide practical
guidance for designing a model structure: e.g., the common model structure assumption can be used
as a justification for using a particular model structure instead of others. As an application,
we then derive a new training framework, which satisfies the data-architecture alignment condition
without assuming it by automatically modifying any given training algorithm dependently on each
data and architecture. Given a standard training algorithm, the framework running its modified
version is empirically shown to maintain competitive (practical) test performances while providing
global convergence guarantees for ResNet-18 with convolutions, skip connections, and batch normalization
with standard benchmark datasets, including MNIST, CIFAR-10, CIFAR-100, Semeion, KMNIST and
SVHN. 