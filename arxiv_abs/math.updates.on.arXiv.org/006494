In this paper, we study the sequential convex programming method with monotone line search (SCP$_{ls}$)
in [46] for a class of difference-of-convex (DC) optimization problems with multiple smooth inequality
constraints. The SCP$_{ls}$ is a representative variant of moving-ball-approximation-type
algorithms [6,10,13,54] for constrained optimization problems. We analyze the convergence rate
of the sequence generated by SCP$_{ls}$ in both nonconvex and convex settings by imposing suitable
Kurdyka-Lojasiewicz (KL) assumptions. Specifically, in the nonconvex settings, we assume that
a special potential function related to the objective and the constraints is a KL function, while
in the convex settings we impose KL assumptions directly on the extended objective function (i.e.,
sum of the objective and the indicator function of the constraint set). A relationship between these
two different KL assumptions is established in the convex settings under additional differentiability
assumptions. We also discuss how to deduce the KL exponent of the extended objective function from
its Lagrangian in the convex settings, under additional assumptions on the constraint functions.
Thanks to this result, the extended objectives of some constrained optimization models such as
minimizing $\ell_1$ subject to logistic/Poisson loss are found to be KL functions with exponent
$\frac12$ under mild assumptions. To illustrate how our results can be applied, we consider SCP$_{ls}$
for minimizing $\ell_{1-2}$ [60] subject to residual error measured by $\ell_2$ norm/Lorentzian
norm [21]. We first discuss how the various conditions required in our analysis can be verified,
and then perform numerical experiments to illustrate the convergence behaviors of SCP$_{ls}$.
