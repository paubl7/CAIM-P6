Recent advances in quantum technologies pave the way for noisy intermediate-scale quantum (NISQ)
devices, where quantum approximation optimization algorithms (QAOAs) constitute promising
candidates for demonstrating tangible quantum advantages based on NISQ devices. In this paper,
we consider the maximum likelihood (ML) detection problem of binary symbols transmitted over a
multiple-input and multiple-output (MIMO) channel, where finding the optimal solution is exponentially
hard using classical computers. Here, we apply the QAOA for the ML detection by encoding the problem
of interest into a level-p QAOA circuit having 2p variational parameters, which can be optimized
by classical optimizers. This level-p QAOA circuit is constructed by applying the prepared Hamiltonian
to our problem and the initial Hamiltonian alternately in p consecutive rounds. More explicitly,
we first encode the optimal solution of the ML detection problem into the ground state of a problem
Hamiltonian. Using the quantum adiabatic evolution technique, we provide both analytical and
numerical results for characterizing the evolution of the eigenvalues of the quantum system used
for ML detection. Then, for level-1 QAOA circuits, we derive the analytical expressions of the expectation
values of the QAOA and discuss the complexity of the QAOA based ML detector. Explicitly, we evaluate
the computational complexity of the classical optimizer used and the storage requirement of simulating
the QAOA. Finally, we evaluate the bit error rate (BER) of the QAOA based ML detector and compare it
both to the classical ML detector and to the classical MMSE detector, demonstrating that the QAOA
based ML detector is capable of approaching the performance of the classical ML detector. This paves
the way for a host of large-scale classical optimization problems to be solved by NISQ computers.
