Network method of moments arXiv:1202.5101 is an important tool for nonparametric network inference.
However, there has been little investigation on accurate descriptions of the sampling distributions
of network moment statistics. In this paper, we present the first higher-order accurate approximation
to the sampling CDF of a studentized network moment by Edgeworth expansion. In sharp contrast to
classical literature on noiseless U-statistics, we show that the Edgeworth expansion of a network
moment statistic as a noisy U-statistic can achieve higher-order accuracy without non-lattice
or smoothness assumptions but just requiring weak regularity conditions. Behind this result is
our surprising discovery that the two typically-hated factors in network analysis, namely, sparsity
and edge-wise observational errors, jointly play a blessing role, contributing a crucial self-smoothing
effect in the network moment statistic and making it analytically tractable. Our assumptions match
the minimum requirements in related literature. For sparse networks, our theory shows a simple
normal approximation achieves a gradually depreciating Berry-Esseen bound as the network becomes
sparser. This result also refines the best previous theoretical result. For practitioners, our
empirical Edgeworth expansion is highly accurate, fast and easy to implement. We demonstrate the
clear advantage of our method by comprehensive simulation studies. We showcase three applications
of our results in network inference. We prove, to our knowledge, the first theoretical guarantee
of higher-order accuracy for some network bootstrap schemes, and moreover, the first theoretical
guidance for selecting the sub-sample size for network sub-sampling. We also derive one-sample
test and Cornish-Fisher confidence interval for a given moment with higher-order accurate controls
of confidence level and type I error, respectively. 