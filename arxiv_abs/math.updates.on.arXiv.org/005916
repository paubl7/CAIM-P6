Inferring linear dependence between time series is central to our understanding of natural and
artificial systems. Unfortunately, the hypothesis tests that are used to determine statistically
significant directed or multivariate relationships from time-series data often yield spurious
associations (Type I errors) or omit causal relationships (Type II errors). This is due to the autocorrelation
present in the analysed time series -- a property that is ubiquitous across diverse applications,
from brain dynamics to climate change. Here we show that, for limited data, this issue cannot be mediated
by fitting a time-series model alone (e.g., in Granger causality or prewhitening approaches),
and instead that the degrees of freedom in statistical tests should be altered to account for the
effective sample size induced by cross-correlations in the observations. This insight enabled
us to derive modified hypothesis tests for any multivariate correlation-based measures of linear
dependence between covariance-stationary time series, including Granger causality and mutual
information with Gaussian marginals. We use both numerical simulations (generated by autoregressive
models and digital filtering) as well as recorded fMRI-neuroimaging data to show that our tests
are unbiased for a variety of stationary time series. Our experiments demonstrate that the commonly
used $F$- and $\chi^2$-tests can induce significant false-positive rates of up to $100\%$ for both
measures, with and without prewhitening of the signals. These findings suggest that many dependencies
reported in the scientific literature may have been, and may continue to be, spuriously reported
or missed if modified hypothesis tests are not used when analysing time series. 