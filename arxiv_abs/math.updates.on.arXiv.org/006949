This work proposes a novel strategy for social learning by introducing the critical feature of adaptation.
In social learning, several distributed agents update continually their belief about a phenomenon
of interest through: i) direct observation of streaming data that they gather locally; and ii) diffusion
of their beliefs through local cooperation with their neighbors. Traditional social learning
implementations are known to learn well the underlying hypothesis (which means that the belief
of every individual agent peaks at the true hypothesis), achieving steady improvement in the learning
accuracy under stationary conditions. However, these algorithms do not perform well under nonstationary
conditions commonly encountered in online learning, exhibiting a significant inertia to track
drifts in the streaming data. In order to address this gap, we propose an Adaptive Social Learning
(ASL) strategy, which relies on a small step-size parameter to tune the adaptation degree. First,
we provide a detailed characterization of the learning performance by means of a steady-state analysis.
Focusing on the small step-size regime, we establish that the ASL strategy achieves consistent
learning under standard global identifiability assumptions. We derive reliable Gaussian approximations
for the probability of error (i.e., of choosing a wrong hypothesis) at each individual agent. We
carry out a large deviations analysis revealing the universal behavior of adaptive social learning:
the error probabilities decrease exponentially fast with the inverse of the step-size, and we characterize
the resulting exponential learning rate. Second, we characterize the adaptation performance
by means of a detailed transient analysis, which allows us to obtain useful analytical formulas
relating the adaptation time to the step-size. 