We develop methodology for estimation and inference using machine learning to enrich economic
models. Our framework takes a standard economic model and recasts the parameters as fully flexible
nonparametric functions, to capture the rich heterogeneity based on potentially high dimensional
or complex observable characteristics. These "parameter functions" retain the interpretability,
economic meaning, and discipline of classical parameters. Deep learning is particularly well-suited
to structured modeling of heterogeneity in economics. We show how to design the network architecture
to match the structure of the economic model, delivering novel methodology that moves deep learning
beyond prediction. We prove convergence rates for the estimated parameter functions. These functions
are the key inputs into the finite-dimensional parameter of inferential interest. We obtain inference
based on a novel influence function calculation that covers any second-stage parameter and any
machine-learning-enriched model that uses a smooth per-observation loss function. No additional
derivations are required. The score can be taken directly to data, using automatic differentiation
if needed. The researcher need only define the original model and define the parameter of interest.
A key insight is that we need not write down the influence function in order to evaluate it on the data.
Our framework gives new results for a host of contexts, covering such diverse examples as price elasticities,
willingness-to-pay, and surplus measures in binary or multinomial choice models, effects of continuous
treatment variables, fractional outcome models, count data, heterogeneous production functions,
and more. We apply our methodology to a large scale advertising experiment for short-term loans.
We show how economically meaningful estimates and inferences can be made that would be unavailable
without our results. 