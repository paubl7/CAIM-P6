Deep learning has rapidly become a widespread tool in both scientific and commercial endeavors.
Milestones of deep learning exceeding human performance have been achieved for a growing number
of tasks over the past several years, across areas as diverse as game-playing, natural-language
translation, and medical-image analysis. However, continued progress is increasingly hampered
by the high energy costs associated with training and running deep neural networks on electronic
processors. Optical neural networks have attracted attention as an alternative physical platform
for deep learning, as it has been theoretically predicted that they can fundamentally achieve higher
energy efficiency than neural networks deployed on conventional digital computers. Here, we experimentally
demonstrate an optical neural network achieving 99% accuracy on handwritten-digit classification
using ~3.2 detected photons per weight multiplication and ~90% accuracy using ~0.64 photons (~$2.4
\times 10^{-19}$ J of optical energy) per weight multiplication. This performance was achieved
using a custom free-space optical processor that executes matrix-vector multiplications in a
massively parallel fashion, with up to ~0.5 million scalar (weight) multiplications performed
at the same time. Using commercially available optical components and standard neural-network
training methods, we demonstrated that optical neural networks can operate near the standard quantum
limit with extremely low optical powers and still achieve high accuracy. Our results provide a proof-of-principle
for low-optical-power operation, and with careful system design including the surrounding electronics
used for data storage and control, open up a path to realizing optical processors that require only
$10^{-16}$ J total energy per scalar multiplication -- which is orders of magnitude more efficient
than current digital processors. 