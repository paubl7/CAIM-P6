Preterm infants are at high risk of developing brain injury in the first days of life as a consequence
of poor cerebral oxygen delivery. Near-infrared spectroscopy (NIRS) is an established technology
developed to monitor regional tissue oxygenation. Detailed waveform analysis of the cerebral
NIRS signal could improve the clinical utility of this method in accurately predicting brain injury.
Frequent transient cerebral oxygen desaturations are commonly observed in extremely preterm
infants, yet their clinical significance remains unclear. The aim of this study was to examine and
compare the performance of two distinct approaches in isolating and extracting transient deflections
within NIRS signals. We optimized three different simultaneous low-pass filtering and total variation
denoising (LPF_TVD) methods and compared their performance with a recently proposed method that
uses singular-spectrum analysis and the discrete cosine transform (SSA_DCT). Parameters for
the LPF_TVD methods were optimized over a grid search using synthetic NIRS-like signals. The SSA_DCT
method was modified with a post-processing procedure to increase sparsity in the extracted components.
Our analysis, using a synthetic NIRS-like dataset, showed that a LPF_TVD method outperformed the
modified SSA_DCT method: median mean-squared error of 0.97 (95% CI: 0.86 to 1.07) was lower for the
LPF_TVD method compared to the modified SSA_DCT method of 1.48 (95% CI: 1.33 to 1.63), P<0.001. The
dual low-pass filter and total variation denoising methods are considerably more computational
efficient, by 3 to 4 orders of magnitude, than the SSA_DCT method. More research is needed to examine
the efficacy of these methods in extracting oxygen desaturation in real NIRS signals. 