With the advent of powerful computer simulation techniques, it is time to move from the widely used
knowledge-guided empirical methods to approaches driven by data science, mainly machine learning
algorithms. Due to their (hidden) smooth composition-property relationships, this strategy
is especially relevant for the development of new glasses. We investigated the predictive performance
of three machine learning algorithms for six different glass properties. For such, we used an extensive
dataset of about 150,000 oxide glasses, which was segmented into smaller sets for each property
investigated. Using the decision tree, k-nearest neighbors, and random forest algorithms, selected
from a previous study of six algorithms, we induced predictive models for glass transition temperature,
liquidus temperature, elastic modulus, thermal expansion coefficient, refractive index, and
the Abbe number. Moreover, each model was induced with the default and tuned hyperparameter values.
We demonstrate that, apart from the elastic modulus (which had the smallest training dataset),
the induced predictive models for the other five properties yield a comparable uncertainty to the
usual data spread. However, for glasses that have extremely low or high values of these properties,
the prediction uncertainty is significantly higher. Finally, as expected, glasses containing
chemical elements that are poorly represented in the training set yielded higher prediction errors.
The method developed here calls attention for the success and also some possible pitfalls of ML methods,
and is beneficial for selecting or developing new glasses with a suitable combination of properties.
The ultimate goal is to use these induced models, which were a necessary step for the inverse task
of recommending the chemical composition that might yield any desired combination of these six
properties. 