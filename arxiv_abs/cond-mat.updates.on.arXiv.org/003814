There is a need for numerical models capable of predicting local accumulation of hydrogen near stress
concentrators and crack tips to prevent and mitigate hydrogen assisted fracture in steels. The
experimental characterisation of trapping parameters in metals, which is required for an accurate
simulation of hydrogen transport, is usually performed through the electropermeation test. In
order to study grain size influence and grain boundary trapping during permeation, two modelling
approaches are explored; a 1D Finite Element model including trap density and binding energy as
input parameters and a polycrystalline model based on the assignment of a lower diffusivity and
solubility to the grain boundaries. Samples of pure iron after two different heat treatments - 950C
for 40 minutes and 1100C for 5 minutes - are tested applying three consecutive rising permeation
steps and three decaying steps. Experimental results show that the finer grain microstructure
promotes a diffusion delay due to grain boundary trapping. The usual methodology for the determination
of trap densities and binding energies is revisited in which the limiting diluted and saturated
cases are considered. To this purpose, apparent diffusivities are fitted including also the influence
of boundary conditions and comparing results provided by the constant concentration with the constant
flux assumption. Grain boundaries are characterised for pure iron with a binding energy between
37.8 and 39.9 kJ/mol and a low trap density but it is numerically demonstrated that saturated or diluted
assumptions are not always verified, and a univocal determination of trapping parameters requires
a broader range of charging conditions for permeation. The relationship between surface parameters,
i.e. charging current, recombination current and surface concentrations, is also studied. 