With the unprecedented shift towards automated urban environments in recent years, a new paradigm
is required to study pedestrian behaviour. Studying pedestrian behaviour in futuristic scenarios
requires modern data sources that consider both the Automated Vehicle (AV) and pedestrian perspectives.
Current open datasets on AVs predominantly fail to account for the latter, as they do not include
an adequate number of events and associated details that involve pedestrian and vehicle interactions.
To address this issue, we propose using Virtual Reality (VR) data as a complementary resource to
current datasets, which can be designed to measure pedestrian behaviour under specific conditions.
In this research, we focus on the context-aware pedestrian trajectory prediction framework for
automated vehicles at mid-block unsignalized crossings. For this purpose, we develop a novel multi-input
network of Long Short-Term Memory (LSTM) and fully connected dense layers. In addition to past trajectories,
the proposed framework incorporates pedestrian head orientations and distance to the upcoming
vehicles as sequential input data. By merging the sequential data with contextual information
of the environment, we train a model to predict the future pedestrian trajectory. Our results show
that the prediction error and overfitting to the training data are reduced by considering contextual
information in the model. To analyze the application of the methods to real AV data, the proposed
framework is trained and applied to pedestrian trajectory extracted from an open-access video
dataset. Finally, by implementing a game theory-based model interpretability method, we provide
detailed insights and propose recommendations to improve the current automated vehicle sensing
systems from a pedestrian-oriented point of view. 