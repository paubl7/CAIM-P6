For robots to navigate and interact more richly with the world around them, they will likely require
a deeper understanding of the world in which they operate. In robotics and related research fields,
the study of understanding is often referred to as semantics, which dictates what does the world
"mean" to a robot, and is strongly tied to the question of how to represent that meaning. With humans
and robots increasingly operating in the same world, the prospects of human-robot interaction
also bring semantics and ontology of natural language into the picture. Driven by need, as well as
by enablers like increasing availability of training data and computational resources, semantics
is a rapidly growing research area in robotics. The field has received significant attention in
the research literature to date, but most reviews and surveys have focused on particular aspects
of the topic: the technical research issues regarding its use in specific robotic topics like mapping
or segmentation, or its relevance to one particular application domain like autonomous driving.
A new treatment is therefore required, and is also timely because so much relevant research has occurred
since many of the key surveys were published. This survey therefore provides an overarching snapshot
of where semantics in robotics stands today. We establish a taxonomy for semantics research in or
relevant to robotics, split into four broad categories of activity, in which semantics are extracted,
used, or both. Within these broad categories we survey dozens of major topics including fundamentals
from the computer vision field and key robotics research areas utilizing semantics, including
mapping, navigation and interaction with the world. The survey also covers key practical considerations,
including enablers like increased data availability and improved computational hardware, and
major application areas where... 