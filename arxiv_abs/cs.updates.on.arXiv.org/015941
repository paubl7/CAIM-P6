Motivation: The activity of the adaptive immune system is governed by T-cells and their specific
T-cell receptors (TCR), which selectively recognize foreign antigens. Recent advances in experimental
techniques have enabled sequencing of TCRs and their antigenic targets (epitopes), allowing to
research the missing link between TCR sequence and epitope binding specificity. Scarcity of data
and a large sequence space make this task challenging, and to date only models limited to a small set
of epitopes have achieved good performance. Here, we establish a k-nearest-neighbor (K-NN) classifier
as a strong baseline and then propose TITAN (Tcr epITope bimodal Attention Networks), a bimodal
neural network that explicitly encodes both TCR sequences and epitopes to enable the independent
study of generalization capabilities to unseen TCRs and/or epitopes. Results: By encoding epitopes
at the atomic level with SMILES sequences, we leverage transfer learning and data augmentation
to enrich the input data space and boost performance. TITAN achieves high performance in the prediction
of specificity of unseen TCRs (ROC-AUC 0.87 in 10-fold CV) and surpasses the results of the current
state-of-the-art (ImRex) by a large margin. Notably, our Levenshtein-distance-based K-NN classifier
also exhibits competitive performance on unseen TCRs. While the generalization to unseen epitopes
remains challenging, we report two major breakthroughs. First, by dissecting the attention heatmaps,
we demonstrate that the sparsity of available epitope data favors an implicit treatment of epitopes
as classes. This may be a general problem that limits unseen epitope performance for sufficiently
complex models. Second, we show that TITAN nevertheless exhibits significantly improved performance
on unseen epitopes and is capable of focusing attention on chemically meaningful molecular structures.
