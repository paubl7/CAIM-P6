Cardiovascular diseases and their associated disorder of heart failure are one of the major death
causes globally, being a priority for doctors to detect and predict its onset and medical consequences.
Artificial Intelligence (AI) allows doctors to discover clinical indicators and enhance their
diagnosis and treatments. Specifically, explainable AI offers tools to improve the clinical prediction
models that experience poor interpretability of their results. This work presents an explainability
analysis and evaluation of a prediction model for heart failure survival by using a dataset that
comprises 299 patients who suffered heart failure. The model employs a data workflow pipeline able
to select the best ensemble tree algorithm as well as the best feature selection technique. Moreover,
different post-hoc techniques have been used for the explainability analysis of the model. The
paper's main contribution is an explainability-driven approach to select the best prediction
model for HF survival based on an accuracy-explainability balance. Therefore, the most balanced
explainable prediction model implements an Extra Trees classifier over 5 selected features (follow-up
time, serum creatinine, ejection fraction, age and diabetes) out of 12, achieving a balanced-accuracy
of 85.1% and 79.5% with cross-validation and new unseen data respectively. The follow-up time is
the most influencing feature followed by serum-creatinine and ejection-fraction. The explainable
prediction model for HF survival presented in this paper would improve a further adoption of clinical
prediction models by providing doctors with intuitions to better understand the reasoning of,
usually, black-box AI clinical solutions, and make more reasonable and data-driven decisions.
