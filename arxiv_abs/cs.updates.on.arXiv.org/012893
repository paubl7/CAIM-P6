Weakly supervised learning (WSL) has recently triggered substantial interest as it mitigates
the lack of pixel-wise annotations, while enabling interpretable models. Given global image labels,
WSL methods yield pixel-level predictions (segmentations). Despite their recent success, mostly
with natural images, such methods could be seriously challenged when the foreground and background
regions have similar visual cues, yielding high false-positive rates in segmentations, as is the
case of challenging histology images. WSL training is commonly driven by standard classification
losses, which implicitly maximize model confidence and find the discriminative regions linked
to classification decisions. Therefore, they lack mechanisms for modeling explicitly non-discriminative
regions and reducing false-positive rates. We propose new regularization terms, which enable
the model to seek both non-discriminative and discriminative regions, while discouraging unbalanced
segmentations. We introduce high uncertainty as a criterion to localize non-discriminative regions
that do not affect classifier decision, and describe it with original Kullback-Leibler (KL) divergence
losses evaluating the deviation of posterior predictions from the uniform distribution. Our KL
terms encourage high uncertainty of the model when the latter takes the latent non-discriminative
regions as input. Our loss integrates: (i) a cross-entropy seeking a foreground, where model confidence
about class prediction is high; (ii) a KL regularizer seeking a background, where model uncertainty
is high; and (iii) log-barrier terms discouraging unbalanced segmentations. Comprehensive experiments
and ablation studies over the public GlaS colon cancer data show substantial improvements over
state-of-the-art WSL methods, and confirm the effect of our new regularizers. Our code is publicly
available. 