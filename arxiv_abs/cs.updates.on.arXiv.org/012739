Scientific research and development relies on the sharing of ideas and artifacts. With the growing
reliance on artificial intelligence (AI) for many different applications, the sharing of code,
data, and models is important to ensure the ability to replicate methods and the democratization
of scientific knowledge. Many high-profile journals and conferences expect code to be submitted
and released with papers. Furthermore, developers often want to release code and models to encourage
development of technology that leverages their frameworks and services. However, AI algorithms
are becoming increasingly powerful and generalized. Ultimately, the context in which an algorithm
is applied can be far removed from that which the developers had intended. A number of organizations
have expressed concerns about inappropriate or irresponsible use of AI and have proposed AI ethical
guidelines and responsible AI initiatives. While such guidelines are useful and help shape policy,
they are not easily enforceable. Governments have taken note of the risks associated with certain
types of AI applications and have passed legislation. While these are enforceable, they require
prolonged scientific and political deliberation. In this paper we advocate the use of licensing
to enable legally enforceable behavioral use conditions on software and data. We argue that licenses
serve as a useful tool for enforcement in situations where it is difficult or time-consuming to legislate
AI usage. Furthermore, by using such licenses, AI developers provide a signal to the AI community,
as well as governmental bodies, that they are taking responsibility for their technologies and
are encouraging responsible use by downstream users. 