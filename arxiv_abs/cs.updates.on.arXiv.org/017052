Generalized Zero-Shot Learning (GZSL) is the task of leveraging semantic information (e.g., attributes)
to recognize the seen and unseen samples, where unseen classes are not observable during training.
It is natural to derive generative models and hallucinate training samples for unseen classes based
on the knowledge learned from the seen samples. However, most of these models suffer from the `generation
shifts', where the synthesized samples may drift from the real distribution of unseen data. In this
paper, we conduct an in-depth analysis on this issue and propose a novel Generation Shifts Mitigating
Flow (GSMFlow) framework, which is comprised of multiple conditional affine coupling layers for
learning unseen data synthesis efficiently and effectively. In particular, we identify three
potential problems that trigger the generation shifts, i.e., semantic inconsistency, variance
decay, and structural permutation and address them respectively. First, to reinforce the correlations
between the generated samples and the respective attributes, we explicitly embed the semantic
information into the transformations in each of the coupling layers. Second, to recover the intrinsic
variance of the synthesized unseen features, we introduce a visual perturbation strategy to diversify
the intra-class variance of generated data and hereby help adjust the decision boundary of the classifier.
Third, to avoid structural permutation in the semantic space, we propose a relative positioning
strategy to manipulate the attribute embeddings, guiding which to fully preserve the inter-class
geometric structure. Experimental results demonstrate that GSMFlow achieves state-of-the-art
recognition performance in both conventional and generalized zero-shot settings. Our code is
available at: https://github.com/uqzhichen/GSMFlow 