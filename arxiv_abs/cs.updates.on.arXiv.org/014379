Neural networks can be successfully used to improve several modules of advanced video coding schemes.
In particular, compression of colour components was shown to greatly benefit from usage of machine
learning models, thanks to the design of appropriate attention-based architectures that allow
the prediction to exploit specific samples in the reference region. However, such architectures
tend to be complex and computationally intense, and may be difficult to deploy in a practical video
coding pipeline. This work focuses on reducing the complexity of such methodologies, to design
a set of simplified and cost-effective attention-based architectures for chroma intra-prediction.
A novel size-agnostic multi-model approach is proposed to reduce the complexity of the inference
process. The resulting simplified architecture is still capable of outperforming state-of-the-art
methods. Moreover, a collection of simplifications is presented in this paper, to further reduce
the complexity overhead of the proposed prediction architecture. Thanks to these simplifications,
a reduction in the number of parameters of around 90% is achieved with respect to the original attention-based
methodologies. Simplifications include a framework for reducing the overhead of the convolutional
operations, a simplified cross-component processing model integrated into the original architecture,
and a methodology to perform integer-precision approximations with the aim to obtain fast and hardware-aware
implementations. The proposed schemes are integrated into the Versatile Video Coding (VVC) prediction
pipeline, retaining compression efficiency of state-of-the-art chroma intra-prediction methods
based on neural networks, while offering different directions for significantly reducing coding
complexity. 