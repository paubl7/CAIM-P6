Optical colonoscopy is an essential diagnostic and prognostic tool for many gastrointestinal
diseases, including cancer screening and staging, intestinal bleeding, diarrhea, abdominal
symptom evaluation, and inflammatory bowel disease assessment. Automated assessment of colonoscopy
is of interest considering the subjectivity present in qualitative human interpretations of colonoscopy
findings. Localization of the camera is essential to interpreting the meaning and context of findings
for diseases evaluated by colonoscopy. In this study, we propose a camera localization system to
estimate the relative location of the camera and classify the colon into anatomical segments. The
camera localization system begins with non-informative frame detection and removal. Then a self-training
end-to-end convolutional neural network is built to estimate the camera motion, where several
strategies are proposed to improve its robustness and generalization on endoscopic videos. Using
the estimated camera motion a camera trajectory can be derived and a relative location index calculated.
Based on the estimated location index, anatomical colon segment classification is performed by
constructing a colon template. The proposed motion estimation algorithm was evaluated on an external
dataset containing the ground truth for camera pose. The experimental results show that the performance
of the proposed method is superior to other published methods. The relative location index estimation
and anatomical region classification were further validated using colonoscopy videos collected
from routine clinical practice. This validation yielded an average accuracy in classification
of 0.754, which is substantially higher than the performances obtained using location indices
built from other methods. 