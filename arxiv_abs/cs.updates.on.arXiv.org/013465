Automated emotion classification could aid those who struggle to recognize emotion, including
children with developmental behavioral conditions such as autism. However, most computer vision
emotion models are trained on adult affect and therefore underperform on child faces. In this study,
we designed a strategy to gamify the collection and the labeling of child affect data in an effort
to boost the performance of automatic child emotion detection to a level closer to what will be needed
for translational digital healthcare. We leveraged our therapeutic smartphone game, GuessWhat,
which was designed in large part for children with developmental and behavioral conditions, to
gamify the secure collection of video data of children expressing a variety of emotions prompted
by the game. Through a secure web interface gamifying the human labeling effort, we gathered and
labeled 2,155 videos, 39,968 emotion frames, and 106,001 labels on all images. With this drastically
expanded pediatric emotion centric database (>30x larger than existing public pediatric affect
datasets), we trained a pediatric emotion classification convolutional neural network (CNN)
classifier of happy, sad, surprised, fearful, angry, disgust, and neutral expressions in children.
The classifier achieved 66.9% balanced accuracy and 67.4% F1-score on the entirety of CAFE as well
as 79.1% balanced accuracy and 78.0% F1-score on CAFE Subset A, a subset containing at least 60% human
agreement on emotions labels. This performance is at least 10% higher than all previously published
classifiers, the best of which reached 56.% balanced accuracy even when combining "anger" and "disgust"
into a single class. This work validates that mobile games designed for pediatric therapies can
generate high volumes of domain-relevant datasets to train state of the art classifiers to perform
tasks highly relevant to precision health efforts. 