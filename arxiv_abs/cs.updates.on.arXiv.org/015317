Graphics Processing Units (GPUs) have been widely used to accelerate artificial intelligence,
physics simulation, medical imaging, and information visualization applications. To improve
GPU performance, GPU hardware designers need to identify performance issues by inspecting a huge
amount of simulator-generated traces. Visualizing the execution traces can reduce the cognitive
burden of users and facilitate making sense of behaviors of GPU hardware components. In this paper,
we first formalize the process of GPU performance analysis and characterize the design requirements
of visualizing execution traces based on a survey study and interviews with GPU hardware designers.
We contribute data and task abstraction for GPU performance analysis. Based on our task analysis,
we propose Daisen, a framework that supports data collection from GPU simulators and provides visualization
of the simulator-generated GPU execution traces. Daisen features a data abstraction and trace
format that can record simulator-generated GPU execution traces. Daisen also includes a web-based
visualization tool that helps GPU hardware designers examine GPU execution traces, identify performance
bottlenecks, and verify performance improvement. Our qualitative evaluation with GPU hardware
designers demonstrates that the design of Daisen reflects the typical workflow of GPU hardware
designers. Using Daisen, participants were able to effectively identify potential performance
bottlenecks and opportunities for performance improvement. The open-sourced implementation
of Daisen can be found at gitlab.com/akita/vis. Supplemental materials including a demo video,
survey questions, evaluation study guide, and post-study evaluation survey are available at osf.io/j5ghq.
