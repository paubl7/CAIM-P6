The term Delay/Disruption-Tolerant Networks (DTN) invented to describe and cover all types of
long-delay, disconnected, intermittently connected networks, where mobility and outages or
scheduled contacts may be experienced. This environment is characterized by frequent network
partitioning, intermittent connectivity, large or variable delay, asymmetric data rate, and
low transmission reliability. There have been routing protocols developed in DTN. However, those
routing algorithms are design based upon specific assumptions. The assumption makes existing
algorithms suitable for specific environment scenarios. Different routing algorithm uses different
relay node selection criteria to select the replication node. Too Frequently forwarding messages
can result in excessive packet loss and large buffer and network overhead. On the other hand, less
frequent transmission leads to a lower delivery ratio. In DTN there is a trade-off off between delivery
ratio and overhead. In this study, we proposed context-adaptive reinforcement learning based
routing(CARL-DTN) protocol to determine optimal replicas of the message based on the real-time
density. Our routing protocol jointly uses a real-time physical context, social-tie strength,
and real-time message context using fuzzy logic in the routing decision. Multi-hop forwarding
probability is also considered for the relay node selection by employing Q-Learning algorithm
to estimate the encounter probability between nodes and to learn about nodes available in the neighbor
by discounting reward. The performance of the proposed protocol is evaluated based on various simulation
scenarios. The result shows that the proposed protocol has better performance in terms of message
delivery ratio and overhead. 