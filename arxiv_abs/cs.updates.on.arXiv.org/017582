Developers often depend on code search engines to obtain solutions for their programming tasks.
However, finding an expected solution containing code examples along with their explanations
is challenging due to several issues. There is a vocabulary mismatch between the search keywords
(the query) and the appropriate solutions. Semantic gap may increase for similar bag of words due
to antonyms and negation. Moreover, documents retrieved by search engines might not contain solutions
containing both code examples and their explanations. So, we propose CRAR (Crowd Answer Recommender)
to circumvent those issues aiming at improving retrieval of relevant answers from Stack Overflow
containing not only the expected code examples for the given task but also their explanations. Given
a programming task, we investigate the effectiveness of combining information retrieval techniques
along with a set of features to enhance the ranking of important threads (i.e., the units containing
questions along with their answers) for the given task and then selects relevant answers contained
in those threads, including semantic features, like word embeddings and sentence embeddings,
for instance, a Convolutional Neural Network (CNN). CRAR also leverages social aspects of Stack
Overflow discussions like popularity to select relevant answers for the tasks. Our experimental
evaluation shows that the combination of the different features performs better than each one individually.
We also compare the retrieval performance with the state-of-art CROKAGE (Crowd Knowledge Answer
Generator), which is also a system aimed at retrieving relevant answers from Stack Overflow. We
show that CRAR outperforms CROKAGE in Mean Reciprocal Rank and Mean Recall with small and medium
effect sizes, respectively. 