The growth in online goods delivery is causing a dramatic surge in urban vehicle traffic from last-mile
deliveries. On the other hand, ride-sharing has been on the rise with the success of ride-sharing
platforms and increased research on using autonomous vehicle technologies for routing and matching.
The future of urban mobility for passengers and goods relies on leveraging new methods that minimize
operational costs and environmental footprints of transportation systems. This paper considers
combining passenger transportation with goods delivery to improve vehicle-based transportation.
Even though the problem has been studied with a defined dynamics model of the transportation system
environment, this paper considers a model-free approach that has been demonstrated to be adaptable
to new or erratic environment dynamics. We propose FlexPool, a distributed model-free deep reinforcement
learning algorithm that jointly serves passengers & goods workloads by learning optimal dispatch
policies from its interaction with the environment. The proposed algorithm pools passengers for
a ride-sharing service and delivers goods using a multi-hop transit method. These flexibilities
decrease the fleet's operational cost and environmental footprint while maintaining service
levels for passengers and goods. Through simulations on a realistic multi-agent urban mobility
platform, we demonstrate that FlexPool outperforms other model-free settings in serving the demands
from passengers & goods. FlexPool achieves 30% higher fleet utilization and 35% higher fuel efficiency
in comparison to (i) model-free approaches where vehicles transport a combination of passengers
& goods without the use of multi-hop transit, and (ii) model-free approaches where vehicles exclusively
transport either passengers or goods. 