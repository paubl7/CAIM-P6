Despite an increasing reliance on fully-automated algorithmic decision making in our day-to-day
lives, human beings still make highly consequential decisions. As frequently seen in business,
healthcare, and public policy, recommendations produced by algorithms are provided to human decision-makers
in order to guide their decisions. While there exists a fast-growing literature evaluating the
bias and fairness of such algorithmic recommendations, an overlooked question is whether they
help humans make better decisions. We develop a statistical methodology for experimentally evaluating
the causal impacts of algorithmic recommendations on human decisions. We also show how to examine
whether algorithmic recommendations improve the fairness of human decisions and derive the optimal
decisions under various settings. We apply the proposed methodology to the first-ever randomized
controlled trial that evaluates the pretrial Public Safety Assessment (PSA) in the criminal justice
system. A goal of the PSA is to help judges decide which arrested individuals should be released.
We find that the PSA provision has little overall impact on the judge's decisions and subsequent
arrestee behavior. However, our analysis provides some potentially suggestive evidence that
the PSA may help avoid unnecessarily harsh decisions for female arrestees regardless of their risk
levels while it encourages the judge to make stricter decisions for male arrestees who are deemed
to be risky. In terms of fairness, the PSA appears to increase the gender bias against males while
having little effect on the existing racial biases of the judge's decisions against non-white males.
Finally, we find that the PSA's recommendations might be too severe unless the cost of a new crime
is sufficiently higher than the cost of a decision that may result in an unnecessary incarceration.
