As we make tremendous advances in machine learning and artificial intelligence technosciences,
there is a renewed understanding in the AI community that we must ensure that humans being are at the
center of our deliberations so that we don't end in technology-induced dystopias. As strongly argued
by Green in his book Smart Enough City, the incorporation of technology in city environs does not
automatically translate into prosperity, wellbeing, urban livability, or social justice. There
is a great need to deliberate on the future of the cities worth living and designing. There are philosophical
and ethical questions involved along with various challenges that relate to the security, safety,
and interpretability of AI algorithms that will form the technological bedrock of future cities.
Several research institutes on human centered AI have been established at top international universities.
Globally there are calls for technology to be made more humane and human-compatible. For example,
Stuart Russell has a book called Human Compatible AI. The Center for Humane Technology advocates
for regulators and technology companies to avoid business models and product features that contribute
to social problems such as extremism, polarization, misinformation, and Internet addiction.
In this paper, we analyze and explore key challenges including security, robustness, interpretability,
and ethical challenges to a successful deployment of AI or ML in human-centric applications, with
a particular emphasis on the convergence of these challenges. We provide a detailed review of existing
literature on these key challenges and analyze how one of these challenges may lead to others or help
in solving other challenges. The paper also advises on the current limitations, pitfalls, and future
directions of research in these domains, and how it can fill the current gaps and lead to better solutions.
