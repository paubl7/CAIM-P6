Objective: We examine how human operators adjust their trust in automation as a result of their moment-to-moment
interaction with automation. Background: Most existing studies measured trust by administering
questionnaires at the end of an experiment. Only a limited number of studies viewed trust as a dynamic
variable that can strengthen or decay over time. Method: Seventy-five participants took part in
an aided memory recognition task. In the task, participants viewed a series of images and later on
performed 40 trials of the recognition task to identify a target image when it was presented with
a distractor. In each trial, participants performed the initial recognition by themselves, received
a recommendation from an automated decision aid, and performed the final recognition. After each
trial, participants reported their trust on a visual analog scale. Results: Outcome bias and contrast
effect significantly influence human operators' trust adjustments. An automation failure leads
to a larger trust decrement if the final outcome is undesirable, and a marginally larger trust decrement
if the human operator succeeds the task by him-/her-self. An automation success engenders a greater
trust increment if the human operator fails the task. Additionally, automation failures have a
larger effect on trust adjustment than automation successes. Conclusion: Human operators adjust
their trust in automation as a result of their moment-to-moment interaction with automation. Their
trust adjustments are significantly influenced by decision-making heuristics/biases. Application:
Understanding the trust adjustment process enables accurate prediction of the operators' moment-to-moment
trust in automation and informs the design of trust-aware adaptive automation. 