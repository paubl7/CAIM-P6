Developing and selecting hearing aids is a time consuming process which is simplified by using objective
models. Previously, the framework for auditory discrimination experiments (FADE) accurately
simulated benefits of hearing aid algorithms with root mean squared prediction errors below 3 dB.
One FADE simulation requires several hours of (un)processed signals, which is obstructive when
the signals have to be recorded. We propose and evaluate a data-reduced FADE version (DARF) which
facilitates simulations with signals that cannot be processed digitally, but that can only be recorded
in real-time. DARF simulates one speech recognition threshold (SRT) with about 30 minutes of recorded
and processed signals of the (German) matrix sentence test. Benchmark experiments were carried
out to compare DARF and standard FADE exhibiting small differences for stationary maskers (1 dB),
but larger differences with strongly fluctuating maskers (5 dB). Hearing impairment and hearing
aid algorithms seemed to reduce the differences. Hearing aid benefits were simulated in terms of
speech recognition with three pairs of real hearing aids in silence ($\geq$8 dB), in stationary
and fluctuating maskers in co-located (stat. 2 dB; fluct. 6 dB), and spatially separated speech
and noise signals (stat. $\geq$8 dB; fluct. 8 dB). The simulations were plausible in comparison
to data from literature, but a comparison with empirical data is still open. DARF facilitates objective
SRT simulations with real devices with unknown signal processing in real environments. Yet, a validation
of DARF for devices with unknown signal processing is still pending since it was only tested with
three similar devices. Nonetheless, DARF could be used for improving as well as for developing or
model-based fitting of hearing aids. 