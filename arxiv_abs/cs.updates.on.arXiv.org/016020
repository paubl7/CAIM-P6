The pervasive adoption of Internet-connected digital services has led to a growing concern in the
personal data privacy of their customers. On the other hand, machine learning (ML) techniques have
been widely adopted by digital service providers to improve operational productivity and customer
satisfaction. ML inevitably accesses and processes users' personal data, which could potentially
breach the relevant privacy protection regulations if not performed carefully. The situation
is exacerbated by the cloud-based implementation of digital services when user data are captured
and stored in distributed locations, hence aggregation of the user data for ML could be a serious
breach of privacy regulations. In this backdrop, Federated Learning (FL) is an emerging area that
allows ML on distributed data without the data leaving their stored location. However, depending
on the nature of the digital services, data captured at different locations may carry different
significance to the business operation, hence a weighted aggregation will be highly desirable
for enhancing the quality of the FL-learned model. Furthermore, to prevent leakage of user data
from the aggregated gradients, cryptographic mechanisms are needed to allow secure aggregation
of FL. In this paper, we propose a privacy-enhanced FL scheme for supporting secure weighted aggregation.
Besides, by devising a verification protocol based on Zero-Knowledge Proof (ZKP), the proposed
scheme is capable of guarding against fraudulent messages from FL participants. Experimental
results show that our scheme is practical and secure. Compared to existing FL approaches, our scheme
achieves secure weighted aggregation with an additional security guarantee against fraudulent
messages with an affordable 1.2 times runtime overheads and 1.3 times communication costs. 