With the significant advancements made in generation of forged video and audio, commonly known
as deepfakes, using deep learning technologies, the problem of its misuse is a well-known issue
now. Recently, a new problem of generating cloned or synthesized human voice of a person is emerging.
AI-based deep learning models can synthesize any person's voice requiring just a few seconds of
audio. With the emerging threat of impersonation attacks using deepfake videos and audios, new
deepfake detectors are need that focuses on both, video and audio. Detecting deepfakes is a challenging
task and researchers have made numerous attempts and proposed several deepfake detection methods.
To develop a good deepfake detector, a handsome amount of good quality dataset is needed that captures
the real world scenarios. Many researchers have contributed in this cause and provided several
deepfake dataset, self generated and in-the-wild. However, almost all of these datasets either
contains deepfake videos or audio. Moreover, the recent deepfake datasets proposed by researchers
have racial bias issues. Hence, there is a crucial need of a good deepfake video and audio deepfake
dataset. To fill this gap, we propose a novel Audio-Video Deepfake dataset (FakeAVCeleb) that not
only contains deepfake videos but respective synthesized cloned audios as well. We generated our
dataset using recent most popular deepfake generation methods and the videos and audios are perfectly
lip-synced with each other. To generate a more realistic dataset, we selected real YouTube videos
of celebrities having four racial backgrounds (Caucasian, Black, East Asian and South Asian) to
counter the racial bias issue. Lastly, we propose a novel multimodal detection method that detects
deepfake videos and audios based on our multimodal Audio-Video deepfake dataset. 