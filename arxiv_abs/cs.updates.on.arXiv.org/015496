Face presentation attack detection plays a critical role in the modern face recognition pipeline.
A face presentation attack detection model with good generalization can be obtained when it is trained
with face images from different input distributions and different types of spoof attacks. In reality,
training data (both real face images and spoof images) are not directly shared between data owners
due to legal and privacy issues. In this paper, with the motivation of circumventing this challenge,
we propose a Federated Face Presentation Attack Detection (FedPAD) framework that simultaneously
takes advantage of rich fPAD information available at different data owners while preserving data
privacy. In the proposed framework, each data center locally trains its own fPAD model. A server
learns a global fPAD model by iteratively aggregating model updates from all data centers without
accessing private data in each of them. To equip the aggregated fPAD model in the server with better
generalization ability to unseen attacks from users, following the basic idea of FedPAD, we further
propose a Federated Generalized Face Presentation Attack Detection (FedGPAD) framework. A federated
domain disentanglement strategy is introduced in FedGPAD, which treats each data center as one
domain and decomposes the fPAD model into domain-invariant and domain-specific parts in each data
center. Two parts disentangle the domain-invariant and domain-specific features from images
in each local data center, respectively. A server learns a global fPAD model by only aggregating
domain-invariant parts of the fPAD models from data centers and thus a more generalized fPAD model
can be aggregated in server. We introduce the experimental setting to evaluate the proposed FedPAD
and FedGPAD frameworks and carry out extensive experiments to provide various insights about federated
learning for fPAD. 