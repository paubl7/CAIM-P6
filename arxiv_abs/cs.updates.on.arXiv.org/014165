This work proposes the continuous conditional generative adversarial network (CcGAN), the first
generative model for image generation conditional on continuous, scalar conditions (termed regression
labels). Existing conditional GANs (cGANs) are mainly designed for categorical conditions (eg,
class labels); conditioning on regression labels is mathematically distinct and raises two fundamental
problems:(P1) Since there may be very few (even zero) real images for some regression labels, minimizing
existing empirical versions of cGAN losses (aka empirical cGAN losses) often fails in practice;(P2)
Since regression labels are scalar and infinitely many, conventional label input methods are not
applicable. The proposed CcGAN solves the above problems, respectively, by (S1) reformulating
existing empirical cGAN losses to be appropriate for the continuous scenario; and (S2) proposing
a naive label input (NLI) method and an improved label input (ILI) method to incorporate regression
labels into the generator and the discriminator. The reformulation in (S1) leads to two novel empirical
discriminator losses, termed the hard vicinal discriminator loss (HVDL) and the soft vicinal discriminator
loss (SVDL) respectively, and a novel empirical generator loss. The error bounds of a discriminator
trained with HVDL and SVDL are derived under mild assumptions in this work. Two new benchmark datasets
(RC-49 and Cell-200) and a novel evaluation metric (Sliding Fr\'echet Inception Distance) are
also proposed for this continuous scenario. Our experiments on the Circular 2-D Gaussians, RC-49,
UTKFace, Cell-200, and Steering Angle datasets show that CcGAN is able to generate diverse, high-quality
samples from the image distribution conditional on a given regression label. Moreover, in these
experiments, CcGAN substantially outperforms cGAN both visually and quantitatively. 