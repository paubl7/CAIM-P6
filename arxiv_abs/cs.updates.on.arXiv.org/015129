Code review plays an important role in software quality control. A typical review process would
involve a careful check of a piece of code in an attempt to find defects and other quality issues/violations.
One type of issues that may impact the quality of the software is code smells - i.e., bad programming
practices that may lead to defects or maintenance issues. Yet, little is known about the extent to
which code smells are identified during code reviews. To investigate the concept behind code smells
identified in code reviews and what actions reviewers suggest and developers take in response to
the identified smells, we conducted an empirical study of code smells in code reviews using the two
most active OpenStack projects (Nova and Neutron). We manually checked 19,146 review comments
obtained by keywords search and random selection, and got 1,190 smell-related reviews to study
the causes of code smells and actions taken against the identified smells. Our analysis found that
1) code smells were not commonly identified in code reviews, 2) smells were usually caused by violation
of coding conventions, 3) reviewers usually provided constructive feedback, including fixing
(refactoring) recommendations to help developers remove smells, and 4) developers generally
followed those recommendations and actioned the changes. Our results suggest that 1) developers
should closely follow coding conventions in their projects to avoid introducing code smells, and
2) review-based detection of code smells is perceived to be a trustworthy approach by developers,
mainly because reviews are context-sensitive (as reviewers are more aware of the context of the
code given that they are part of the project's development team). 