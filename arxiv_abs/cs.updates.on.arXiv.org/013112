Our modern history of deep learning follows the arc of famous emergent disciplines in engineering
(e.g. aero- and fluid dynamics) when theory lagged behind successful practical applications.
Viewing neural networks from a dynamical systems perspective, in this work, we propose a novel characterization
of deep neural networks as pointwise affine maps, making them accessible to a broader range of analysis
methods to help close the gap between theory and practice. We begin by showing the equivalence of
neural networks with parameter-varying affine maps parameterized by the state (feature) vector.
As the paper's main results, we provide necessary and sufficient conditions for the global stability
of generic deep feedforward neural networks. Further, we identify links between the spectral properties
of layer-wise weight parametrizations, different activation functions, and their effect on the
overall network's eigenvalue spectra. We analyze a range of neural networks with varying weight
initializations, activation functions, bias terms, and depths. Our view of neural networks as
affine parameter varying maps allows us to "crack open the black box" of global neural network dynamical
behavior through visualization of stationary points, regions of attraction, state-space partitioning,
eigenvalue spectra, and stability properties. Our analysis covers neural networks both as an end-to-end
function and component-wise without simplifying assumptions or approximations. The methods
we develop here provide tools to establish relationships between global neural dynamical properties
and their constituent components which can aid in the principled design of neural networks for dynamics
modeling and optimal control. 