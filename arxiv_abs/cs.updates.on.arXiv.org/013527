Although convolutional neural networks (CNN) achieve high diagnostic accuracy for detecting
Alzheimer's disease (AD) dementia based on magnetic resonance imaging (MRI) scans, they are not
yet applied in clinical routine. One important reason for this is a lack of model comprehensibility.
Recently developed visualization methods for deriving CNN relevance maps may help to fill this
gap. We investigated whether models with higher accuracy also rely more on discriminative brain
regions predefined by prior knowledge. We trained a CNN for the detection of AD in N=663 T1-weighted
MRI scans of patients with dementia and amnestic mild cognitive impairment (MCI) and verified the
accuracy of the models via cross-validation and in three independent samples including N=1655
cases. We evaluated the association of relevance scores and hippocampus volume to validate the
clinical utility of this approach. To improve model comprehensibility, we implemented an interactive
visualization of 3D CNN relevance maps. Across three independent datasets, group separation showed
high accuracy for AD dementia vs. controls (AUC$\geq$0.92) and moderate accuracy for MCI vs. controls
(AUC$\approx$0.75). Relevance maps indicated that hippocampal atrophy was considered as the
most informative factor for AD detection, with additional contributions from atrophy in other
cortical and subcortical regions. Relevance scores within the hippocampus were highly correlated
with hippocampal volumes (Pearson's r$\approx$-0.81). The relevance maps highlighted atrophy
in regions that we had hypothesized a priori. This strengthens the comprehensibility of the CNN
models, which were trained in a purely data-driven manner based on the scans and diagnosis labels.
The high hippocampus relevance scores and high performance achieved in independent samples support
the validity of the CNN models in the detection of AD-related MRI abnormalities. 