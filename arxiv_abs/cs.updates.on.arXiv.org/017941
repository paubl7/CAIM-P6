Due to the high efficiency and less weather dependency, autonomous greenhouses provide an ideal
solution to meet the increasing demand for fresh food. However, managers are faced with some challenges
in finding appropriate control strategies for crop growth, since the decision space of the greenhouse
control problem is an astronomical number. Therefore, an intelligent closed-loop control framework
is highly desired to generate an automatic control policy. As a powerful tool for optimal control,
reinforcement learning (RL) algorithms can surpass human beings' decision-making and can also
be seamlessly integrated into the closed-loop control framework. However, in complex real-world
scenarios such as agricultural automation control, where the interaction with the environment
is time-consuming and expensive, the application of RL algorithms encounters two main challenges,
i.e., sample efficiency and safety. Although model-based RL methods can greatly mitigate the efficiency
problem of greenhouse control, the safety problem has not got too much attention. In this paper,
we present a model-based robust RL framework for autonomous greenhouse control to meet the sample
efficiency and safety challenges. Specifically, our framework introduces an ensemble of environment
models to work as a simulator and assist in policy optimization, thereby addressing the low sample
efficiency problem. As for the safety concern, we propose a sample dropout module to focus more on
worst-case samples, which can help improve the adaptability of the greenhouse planting policy
in extreme cases. Experimental results demonstrate that our approach can learn a more effective
greenhouse planting policy with better robustness than existing methods. 