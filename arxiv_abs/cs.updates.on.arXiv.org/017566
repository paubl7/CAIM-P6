Existing person re-identification (Re-ID) works mostly consider a short-term search problem
assuming unchanged clothes and personal appearance. However, in real-world we often dress differently
across locations, time, dates, seasons, weather, and events. As a result, the existing methods
are unsuitable for long-term person Re-ID with clothes change involved. Whilst there are several
recent long-term Re-ID attempts, a large realistic dataset with clothes change is lacking and indispensable
for enabling extensive study as already experienced in short-term Re-ID setting. In this work,
we contribute a large, realistic long-term person identification benchmark. It consists of 178K
bounding boxes from 1.1K person identities, collected and constructed over 12 months. Unique characteristics
of this dataset include: (1) Natural/native personal appearance (e.g., clothes and hair style)
variations: The clothes-change and dressing styles all are highly diverse, with the reappearing
gap in time ranging from minutes, hours, and days to weeks, months, seasons, and years. (2) Diverse
walks of life: Persons across a wide range of ages and professions appear in different weather conditions
(e.g., sunny, cloudy, windy, rainy, snowy, extremely cold) and events (e.g., working, leisure,
daily activities). (3) Rich camera setups: The raw videos were recorded by 17 outdoor security cameras
with various resolutions operating in a real-world surveillance system for a wide and dense block.
(4) Largest scale: It covers the largest number of (17) cameras, (1, 121) identities, and (178, 407)
bounding boxes, as compared to alternative datasets. Our dataset and benchmark codes are available
on https://github.com/PengBoXiangShang/deepchange. 