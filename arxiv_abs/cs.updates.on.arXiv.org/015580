Quantitative bone single-photon emission computed tomography (QBSPECT) has the potential to
provide a better quantitative assessment of bone metastasis than planar bone scintigraphy due
to its ability to better quantify activity in overlapping structures. An important element of assessing
response of bone metastasis is accurate image segmentation. However, limited by the properties
of QBSPECT images, the segmentation of anatomical regions-of-interests (ROIs) still relies heavily
on the manual delineation by experts. This work proposes a fast and robust automated segmentation
method for partitioning a QBSPECT image into lesion, bone, and background. We present a new unsupervised
segmentation loss function and its semi- and supervised variants for training a convolutional
neural network (ConvNet). The loss functions were developed based on the objective function of
the classical Fuzzy C-means (FCM) algorithm. We conducted a comprehensive study to compare our
proposed methods with ConvNets trained using supervised loss functions and conventional clustering
methods. The Dice similarity coefficient (DSC) and several other metrics were used as figures of
merit as applied to the task of delineating lesion and bone in both simulated and clinical SPECT/CT
images. We experimentally demonstrated that the proposed methods yielded good segmentation results
on a clinical dataset even though the training was done using realistic simulated images. A ConvNet-based
image segmentation method that uses novel loss functions was developed and evaluated. The method
can operate in unsupervised, semi-supervised, or fully-supervised modes depending on the availability
of annotated training data. The results demonstrated that the proposed method provides fast and
robust lesion and bone segmentation for QBSPECT/CT. The method can potentially be applied to other
medical image segmentation applications. 