The support of coexisting ultra-reliable and low-latency (URLL) and enhanced Mobile BroadBand
(eMBB) services is a key challenge for the current and future wireless communication networks.
Those two types of services introduce strict, and in some time conflicting, resource allocation
requirements that may result in a power-struggle between reliability, latency, and resource utilization
in wireless networks. The difficulty in addressing that challenge could be traced back to the predominant
reactive approach in allocating the wireless resources. This allocation operation is carried
out based on received service requests and global network statistics, which may not incorporate
a sense of \textit{proaction}. Therefore, this paper proposes a novel framework termed \textit{service
identification} to develop novel proactive resource allocation algorithms. The developed framework
is based on visual data (captured for example by RGB cameras) and deep learning (e.g., deep neural
networks). The ultimate objective of this framework is to equip future wireless networks with the
ability to analyze user behavior, anticipate incoming services, and perform proactive resource
allocation. To demonstrate the potential of the proposed framework, a wireless network scenario
with two coexisting URLL and eMBB services is considered, and two deep learning algorithms are designed
to utilize RGB video frames and predict incoming service type and its request time. An evaluation
dataset based on the considered scenario is developed and used to evaluate the performance of the
two algorithms. The results confirm the anticipated value of proaction to wireless networks; the
proposed models enable efficient network performance ensuring more than $85\%$ utilization of
the network resources at $\sim 98\%$ reliability. This highlights a promising direction for the
future vision-aided wireless communication networks. 