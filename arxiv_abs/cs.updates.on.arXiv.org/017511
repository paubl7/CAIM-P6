In subjective full-reference image quality assessment, differences between perceptual image
qualities of the reference image and its distorted versions are evaluated, often using degradation
category ratings (DCR). However, the DCR has been criticized since differences between rating
categories on this ordinal scale might not be perceptually equidistant, and observers may have
different understandings of the categories. Pair comparisons (PC) of distorted images, followed
by Thurstonian reconstruction of scale values, overcome these problems. In addition, PC is more
sensitive than DCR, and it can provide scale values in fractional, just noticeable difference (JND)
units that express a precise perceptional interpretation. Still, the comparison of images of nearly
the same quality can be difficult. We introduce boosting techniques embedded in more general triplet
comparisons (TC) that increase the sensitivity even more. Boosting amplifies the artefacts of
distorted images, enlarges their visual representation by zooming, increases the visibility
of the distortions by a flickering effect, or combines some of the above. Experimental results show
the effectiveness of boosted TC for seven types of distortion. We crowdsourced over 1.7 million
responses to triplet questions. A detailed analysis shows that boosting increases the discriminatory
power and allows to reduce the number of subjective ratings without sacrificing the accuracy of
the resulting relative image quality values. Our technique paves the way to fine-grained image
quality datasets, allowing for more distortion levels, yet with high-quality subjective annotations.
We also provide the details for Thurstonian scale reconstruction from TC and our annotated dataset,
KonFiG-IQA, containing 10 source images, processed using 7 distortion types at 12 or even 30 levels,
uniformly spaced over a span of 3 JND units. 