The sensitivity to blockages is a key challenge for the high-frequency (5G millimeter wave and 6G
sub-terahertz) wireless networks. Since these networks mainly rely on line-of-sight (LOS) links,
sudden link blockages highly threatens the reliability of the networks. Further, when the LOS link
is blocked, the network typically needs to hand off the user to another LOS basestation, which may
incur critical time latency, especially if a search over a large codebook of narrow beams is needed.
A promising way to tackle the reliability and latency challenges lies in enabling proaction in wireless
networks. Proaction basically allows the network to anticipate blockages, especially dynamic
blockages, and initiate user hand-off beforehand. This paper presents a complete machine learning
framework for enabling proaction in wireless networks relying on visual data captured, for example,
by RGB cameras deployed at the base stations. In particular, the paper proposes a vision-aided wireless
communication solution that utilizes bimodal machine learning to perform proactive blockage
prediction and user hand-off. The bedrock of this solution is a deep learning algorithm that learns
from visual and wireless data how to predict incoming blockages. The predictions of this algorithm
are used by the wireless network to proactively initiate hand-off decisions and avoid any unnecessary
latency. The algorithm is developed on a vision-wireless dataset generated using the ViWi data-generation
framework. Experimental results on two basestations with different cameras indicate that the
algorithm is capable of accurately detecting incoming blockages more than $\sim 90\%$ of the time.
Such blockage prediction ability is directly reflected in the accuracy of proactive hand-off,
which also approaches $87\%$. This highlights a promising direction for enabling high reliability
and low latency in future wireless networks. 