Within intelligent tutoring systems, considerable research has investigated hints, including
how to generate data-driven hints, what hint content to present, and when to provide hints for optimal
learning outcomes. However, less attention has been paid to how hints are presented. In this paper,
we propose a new hint delivery mechanism called "Assertions" for providing unsolicited hints in
a data-driven intelligent tutor. Assertions are partially-worked example steps designed to appear
within a student workspace, and in the same format as student-derived steps, to show students a possible
subgoal leading to the solution. We hypothesized that Assertions can help address the well-known
hint avoidance problem. In systems that only provide hints upon request, hint avoidance results
in students not receiving hints when they are needed. Our unsolicited Assertions do not seek to improve
student help-seeking, but rather seek to ensure students receive the help they need. We contrast
Assertions with Messages, text-based, unsolicited hints that appear after student inactivity.
Our results show that Assertions significantly increase unsolicited hint usage compared to Messages.
Further, they show a significant aptitude-treatment interaction between Assertions and prior
proficiency, with Assertions leading students with low prior proficiency to generate shorter
(more efficient) posttest solutions faster. We also present a clustering analysis that shows patterns
of productive persistence among students with low prior knowledge when the tutor provides unsolicited
help in the form of Assertions. Overall, this work provides encouraging evidence that hint presentation
can significantly impact how students use them and using Assertions can be an effective way to address
help avoidance. 