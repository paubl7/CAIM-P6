We consider a sequential blocked matching (SBM) model where strategic agents repeatedly report
ordinal preferences over a set of services to a central mechanism. The central mechanism's goal
is to elicit agents' true preferences and design a policy that matches services to agents in order
to maximize the expected social welfare with the added constraint that each matched service can
be \emph{blocked} or unavailable for a number of time periods. Naturally, SBM models the repeated
allocation of reusable services to a set of agents where each allocated service becomes unavailable
for a fixed duration. We first consider the offline SBM setting, where the the strategic agents are
aware of the true preferences. We measure the performance of any policy by \emph{distortion}, the
worst-case multiplicative approximation guaranteed by any policy. For the setting with $S$ services,
we establish lower bounds of $\Omega(S)$ and $\Omega(\sqrt{S})$ on the distortions of any deterministic
and randomised mechanisms, respectively. We complement these results by providing approximately
truthful, measured by \emph{incentive ratio}, deterministic and randomised policies based on
the repeated application of random serial dictatorship that match the lower bounds. Our results
show that there is a significant improvement if one considers the class of randomised policies.
Finally, we consider the online SBM setting with bandit feedback where each agent is unaware of her
true preference, and the center must facilitate each agent in the learning of agent's preference
through the matching of services over time. We design an approximately truthful mechanism based
on the Explore-then-Commit paradigm, which achieves logarithmic dynamic approximate regret.
