Graph convolution network (GCN) have achieved state-of-the-art performance in the task of node
prediction in the graph structure. However, with the gradual various of graph attack methods, there
are lack of research on the robustness of GCN. In this paper, we prove the reason why GCN is vulnerable
to attack: only training another GCN model can find the vulnerability of the target GCN model. To
solve that, we propose a GCN model which is robust to attacks. By hiding the node's position in the
Gaussian noise, the attacker will not be able to modify the connection information of the graph node,
thus immune to the attack. Considering attackers usually modify the connection to interfere the
prediction results of the target node, so, by hiding the connection of the graph in the noise through
adversarial training, accurate node prediction can be completed only by the node number rather
than its specific position in the graph, thus let the nodes in the graph are no longer related to the
graph itself, that is to say, make the node anonymous. Specifically, we first demonstrated the key
to determine the embedding of a specific node: the row corresponding to the node of the eigenmatrix
of the Laplace matrix, by target it as the output of the generator, we take the corresponding noise
as input. The generator will try to find the correct position of the node in the graph. Then the encoder
and decoder are spliced both in discriminator, so that after adversarial training, the generator
and discriminator can cooperate to complete the node prediction. Finally, All node positions can
generated by noise at the same time, that is to say, the generator will hides all the connection information
of the graph structure. The evaluation shows that we only need to obtain the initial features and
node numbers of the nodes to complete the node prediction, and the accuracy did not decrease, but
increased by 0.0293. 