Histopathological images of tumors contain abundant information about how tumors grow and how
they interact with their micro-environment. Better understanding of tissue phenotypes in these
images could reveal novel determinants of pathological processes underlying cancer, and in turn
improve diagnosis and treatment options. Advances of Deep learning makes it ideal to achieve those
goals, however, its application is limited by the cost of high quality labels from patients data.
Unsupervised learning, in particular, deep generative models with representation learning properties
provides an alternative path to further understand cancer tissue phenotypes, capturing tissue
morphologies. In this paper, we develop a framework which allows GANs to capture key tissue features
and uses these characteristics to give structure to its latent space. To this end, we trained our
model on two different datasets, an H&E colorectal cancer tissue from the National Center for Tumor
diseases (NCT) and an H&E breast cancer tissue from the Netherlands Cancer Institute (NKI) and Vancouver
General Hospital (VGH). Composed of 86 slide images and 576 TMAs respectively. We show that our model
generates high quality images, with a FID of 16.65 (breast cancer) and 32.05 (colorectal cancer).
We further assess the quality of the images with cancer tissue characteristics (e.g. count of cancer,
lymphocytes, or stromal cells), using quantitative information to calculate the FID and showing
consistent performance of 9.86. Additionally, the latent space of our model shows an interpretable
structure and allows semantic vector operations that translate into tissue feature transformations.
Furthermore, ratings from two expert pathologists found no significant difference between our
generated tissue images from real ones. The code, images, and pretrained models are available at
https://github.com/AdalbertoCq/Pathology-GAN 