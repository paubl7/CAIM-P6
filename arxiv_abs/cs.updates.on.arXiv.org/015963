Though deep neural network models exhibit outstanding performance for various applications,
their large model size and extensive floating-point operations render deployment on mobile computing
platforms a major challenge, and, in particular, on Internet of Things devices. One appealing solution
is model quantization that reduces the model size and uses integer operations commonly supported
by microcontrollers . To this end, a 1-bit quantized DNN model or deep binary neural network maximizes
the memory efficiency, where each parameter in a BNN model has only 1-bit. In this paper, we propose
a reconfigurable BNN (RBNN) to further amplify the memory efficiency for resource-constrained
IoT devices. Generally, the RBNN can be reconfigured on demand to achieve any one of M (M>1) distinct
tasks with the same parameter set, thus only a single task determines the memory requirements. In
other words, the memory utilization is improved by times M. Our extensive experiments corroborate
that up to seven commonly used tasks can co-exist (the value of M can be larger). These tasks with a
varying number of classes have no or negligible accuracy drop-off on three binarized popular DNN
architectures including VGG, ResNet, and ReActNet. The tasks span across different domains, e.g.,
computer vision and audio domains validated herein, with the prerequisite that the model architecture
can serve those cross-domain tasks. To protect the intellectual property of an RBNN model, the reconfiguration
can be controlled by both a user key and a device-unique root key generated by the intrinsic hardware
fingerprint. By doing so, an RBNN model can only be used per paid user per authorized device, thus
benefiting both the user and the model provider. 