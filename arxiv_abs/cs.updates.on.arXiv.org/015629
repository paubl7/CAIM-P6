Research seeks to apply Artificial Intelligence (AI) to scale and extend the capabilities of human
operators to defend networks. A fundamental problem that hinders the generalization of successful
AI approaches -- i.e., beating humans at playing games -- is that network defense cannot be defined
as a single game with a fixed set of rules. Our position is that network defense is better characterized
as a collection of games with uncertain and possibly drifting rules. Hence, we propose to define
network defense tasks as distributions of network environments, to: (i) enable research to apply
modern AI techniques, such as unsupervised curriculum learning and reinforcement learning for
network defense; and, (ii) facilitate the design of well-defined challenges that can be used to
compare approaches for autonomous cyberdefense. To demonstrate that an approach for autonomous
network defense is practical it is important to be able to reason about the boundaries of its applicability.
Hence, we need to be able to define network defense tasks that capture sets of adversarial tactics,
techniques, and procedures (TTPs); quality of service (QoS) requirements; and TTPs available
to defenders. Furthermore, the abstractions to define these tasks must be extensible; must be backed
by well-defined semantics that allow us to reason about distributions of environments; and should
enable the generation of data and experiences from which an agent can learn. Our approach named Network
Environment Design for Autonomous Cyberdefense inspired the architecture of FARLAND, a Framework
for Advanced Reinforcement Learning for Autonomous Network Defense, which we use at MITRE to develop
RL network defenders that perform blue actions from the MITRE Shield matrix against attackers with
TTPs that drift from MITRE ATT&CK TTPs. 