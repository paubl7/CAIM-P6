Over the last two years, The Alan Turing Institute and the Information Commissioner's Office (ICO)
have been working together to discover ways to tackle the difficult issues surrounding explainable
AI. The ultimate product of this joint endeavour, Explaining decisions made with AI, published
in May 2020, is the most comprehensive practical guidance on AI explanation produced anywhere to
date. We have put together this workbook to help support the uptake of that guidance. The goal of the
workbook is to summarise some of main themes from Explaining decisions made with AI and then to provide
the materials for a workshop exercise that has been built around a use case created to help you gain
a flavour of how to put the guidance into practice. In the first three sections, we run through the
basics of Explaining decisions made with AI. We provide a precis of the four principles of AI explainability,
the typology of AI explanations, and the tasks involved in the explanation-aware design, development,
and use of AI/ML systems. We then provide some reflection questions, which are intended to be a launching
pad for group discussion, and a starting point for the case-study-based exercise that we have included
as Appendix B. In Appendix A, we go into more detailed suggestions about how to organise the workshop.
These recommendations are based on two workshops we had the privilege of co-hosting with our colleagues
from the ICO and Manchester Metropolitan University in January 2021. The participants of these
workshops came from both the private and public sectors, and we are extremely grateful to them for
their energy, enthusiasm, and tremendous insight. This workbook would simply not exist without
the commitment and keenness of all our collaborators and workshop participants. 