We present a new deep learning method, dubbed FibrilNet, for tracing chromospheric fibrils in Halpha
images of solar observations. Our method consists of a data pre-processing component that prepares
training data from a threshold-based tool, a deep learning model implemented as a Bayesian convolutional
neural network for probabilistic image segmentation with uncertainty quantification to predict
fibrils, and a post-processing component containing a fibril-fitting algorithm to determine
fibril orientations. The FibrilNet tool is applied to high-resolution Halpha images from an active
region (AR 12665) collected by the 1.6 m Goode Solar Telescope (GST) equipped with high-order adaptive
optics at the Big Bear Solar Observatory (BBSO). We quantitatively assess the FibrilNet tool, comparing
its image segmentation algorithm and fibril-fitting algorithm with those employed by the threshold-based
tool. Our experimental results and major findings are summarized as follows. First, the image segmentation
results (i.e., detected fibrils) of the two tools are quite similar, demonstrating the good learning
capability of FibrilNet. Second, FibrilNet finds more accurate and smoother fibril orientation
angles than the threshold-based tool. Third, FibrilNet is faster than the threshold-based tool
and the uncertainty maps produced by FibrilNet not only provide a quantitative way to measure the
confidence on each detected fibril, but also help identify fibril structures that are not detected
by the threshold-based tool but are inferred through machine learning. Finally, we apply FibrilNet
to full-disk Halpha images from other solar observatories and additional high-resolution Halpha
images collected by BBSO/GST, demonstrating the tool's usability in diverse datasets. 