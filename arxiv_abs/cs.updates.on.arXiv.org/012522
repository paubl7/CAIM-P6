A number of methods based on deep learning have been applied to medical image segmentation and have
achieved state-of-the-art performance. Due to the importance of chest x-ray data in studying COVID-19,
there is a demand for state-of-the-art models capable of precisely segmenting soft tissue on the
chest x-rays. The dataset for exploring best segmentation model is from Montgomery and Shenzhen
hospital which had opened in 2014. The most famous technique is U-Net which has been used to many medical
datasets including the Chest X-rays. However, most variant U-Nets mainly focus on extraction of
contextual information and skip connections. There is still a large space for improving extraction
of spatial features. In this paper, we propose a dual encoder fusion U-Net framework for Chest X-rays
based on Inception Convolutional Neural Network with dilation, Densely Connected Recurrent Convolutional
Neural Network, which is named DEFU-Net. The densely connected recurrent path extends the network
deeper for facilitating contextual feature extraction. In order to increase the width of network
and enrich representation of features, the inception blocks with dilation are adopted. The inception
blocks can capture globally and locally spatial information from various receptive fields. At
the same time, the two paths are fused by summing features, thus preserving the contextual and spatial
information for decoding part. This multi-learning-scale model is benefiting in Chest X-ray dataset
from two different manufacturers (Montgomery and Shenzhen hospital). The DEFU-Net achieves the
better performance than basic U-Net, residual U-Net, BCDU-Net, R2U-Net and attention R2U-Net.
This model has proved the feasibility for mixed dataset and approaches state-of-the-art. The source
code for this proposed framework is public https://github.com/uceclz0/DEFU-Net. 