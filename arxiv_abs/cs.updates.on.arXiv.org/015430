In recent years, deep learning techniques have outperformed traditional models in many machine
learning tasks. Deep neural networks have successfully been applied to address time series forecasting
problems, which is a very important topic in data mining. They have proved to be an effective solution
given their capacity to automatically learn the temporal dependencies present in time series.
However, selecting the most convenient type of deep neural network and its parametrization is a
complex task that requires considerable expertise. Therefore, there is a need for deeper studies
on the suitability of all existing architectures for different forecasting tasks. In this work,
we face two main challenges: a comprehensive review of the latest works using deep learning for time
series forecasting; and an experimental study comparing the performance of the most popular architectures.
The comparison involves a thorough analysis of seven types of deep learning models in terms of accuracy
and efficiency. We evaluate the rankings and distribution of results obtained with the proposed
models under many different architecture configurations and training hyperparameters. The datasets
used comprise more than 50000 time series divided into 12 different forecasting problems. By training
more than 38000 models on these data, we provide the most extensive deep learning study for time series
forecasting. Among all studied models, the results show that long short-term memory (LSTM) and
convolutional networks (CNN) are the best alternatives, with LSTMs obtaining the most accurate
forecasts. CNNs achieve comparable performance with less variability of results under different
parameter configurations, while also being more efficient. 