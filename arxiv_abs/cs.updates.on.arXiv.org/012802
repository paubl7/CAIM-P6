This review intends to summarise the key qualities, current challenges and future perspectives
faced by the GA technique. Their implicit parallelism and evolutionary operators allow an optimal
balance between exploration and exploitation. They thrive in identifying good solutions in large,
rugged search spaces. They have desirable convergence properties, offer high flexibility, and
impose very few assumptions on the nature of the solutions being evolved. They allow a realistic
modelling of evolutionary systems and innovation dynamics. Often criticised for their computational
complexity, GAs' computational efficiency is a first challenge to address to handle dynamic or
more complex problems, likely with further use of parallelism and GPU computing. The difficult
configuration of GAs parameters, determinant to their performance, remains an open area of investigation.
The specifications of the canonical GA, notably the choice of individual representation, the design
of the fitness landscape, and initial population sampling, impose some implicit constraints on
the search space being explored, and the solutions being evolved, requiring further innovations
to achieve open-ended evolution and robustness. Most of GAs achievements have so far been achieved
from a restricted subset of our knowledge on natural evolution and genetics. We argue that a deeper,
renewed inspiration from the state of the art of biology and genetic research, carries the potential
for fundamental discoveries in GA design. The evolution of evolvability, the ability to produce
the most improving kind of variation for selection, interactions between mutations, pleiotropy,
the modularity of biological networks, are only few examples of such many promising future directions.
By expanding self-adaptation, a novel class of GAs oriented towards artificial life and open ended
evolution can emerge. 