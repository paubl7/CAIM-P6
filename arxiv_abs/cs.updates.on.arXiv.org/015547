To meet the needs of a growing world population, we need to increase the global agricultural yields
by employing modern, precision, and automated farming methods. In the recent decade, high-throughput
plant phenotyping techniques, which combine non-invasive image analysis and machine learning,
have been successfully applied to identify and quantify plant health and diseases. However, these
image-based machine learning usually do not consider plant stress's progressive or temporal nature.
This time-invariant approach also requires images showing severe signs of stress to ensure high
confidence detections, thereby reducing this approach's feasibility for early detection and
recovery of plants under stress. In order to overcome the problem mentioned above, we propose a temporal
analysis of the visual changes induced in the plant due to stress and apply it for the specific case
of water stress identification in Chickpea plant shoot images. For this, we have considered an image
dataset of two chickpea varieties JG-62 and Pusa-372, under three water stress conditions; control,
young seedling, and before flowering, captured over five months. We then develop an LSTM-CNN architecture
to learn visual-temporal patterns from this dataset and predict the water stress category with
high confidence. To establish a baseline context, we also conduct a comparative analysis of the
CNN architecture used in the proposed model with the other CNN techniques used for the time-invariant
classification of water stress. The results reveal that our proposed LSTM-CNN model has resulted
in the ceiling level classification performance of \textbf{98.52\%} on JG-62 and \textbf{97.78\%}
on Pusa-372 and the chickpea plant data. Lastly, we perform an ablation study to determine the LSTM-CNN
model's performance on decreasing the amount of temporal session data used for training. 