Since their inception, learning techniques under the Reservoir Computing paradigm have shown
a great modeling capability for recurrent systems without the computing overheads required for
other approaches. Among them, different flavors of echo state networks have attracted many stares
through time, mainly due to the simplicity and computational efficiency of their learning algorithm.
However, these advantages do not compensate for the fact that echo state networks remain as black-box
models whose decisions cannot be easily explained to the general audience. This work addresses
this issue by conducting an explainability study of Echo State Networks when applied to learning
tasks with time series, image and video data. Specifically, the study proposes three different
techniques capable of eliciting understandable information about the knowledge grasped by these
recurrent models, namely, potential memory, temporal patterns and pixel absence effect. Potential
memory addresses questions related to the effect of the reservoir size in the capability of the model
to store temporal information, whereas temporal patterns unveils the recurrent relationships
captured by the model over time. Finally, pixel absence effect attempts at evaluating the effect
of the absence of a given pixel when the echo state network model is used for image and video classification.
We showcase the benefits of our proposed suite of techniques over three different domains of applicability:
time series modeling, image and, for the first time in the related literature, video classification.
Our results reveal that the proposed techniques not only allow for a informed understanding of the
way these models work, but also serve as diagnostic tools capable of detecting issues inherited
from data (e.g. presence of hidden bias). 