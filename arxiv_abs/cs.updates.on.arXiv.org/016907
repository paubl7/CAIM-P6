We focus on electronic theses and dissertations (ETDs), aiming to improve access and expand their
utility, since more than 6 million are publicly available, and they constitute an important corpus
to aid research and education across disciplines. The corpus is growing as new born-digital documents
are included, and since millions of older theses and dissertations have been converted to digital
form to be disseminated electronically in institutional repositories. In ETDs, as with other scholarly
works, figures and tables can communicate a large amount of information in a concise way. Although
methods have been proposed for extracting figures and tables from born-digital PDFs, they do not
work well with scanned ETDs. Considering this problem, our assessment of state-of-the-art figure
extraction systems is that the reason they do not function well on scanned PDFs is that they have only
been trained on born-digital documents. To address this limitation, we present ScanBank, a new
dataset containing 10 thousand scanned page images, manually labeled by humans as to the presence
of the 3.3 thousand figures or tables found therein. We use this dataset to train a deep neural network
model based on YOLOv5 to accurately extract figures and tables from scanned ETDs. We pose and answer
important research questions aimed at finding better methods for figure extraction from scanned
documents. One of those concerns the value for training, of data augmentation techniques applied
to born-digital documents which are used to train models better suited for figure extraction from
scanned documents. To the best of our knowledge, ScanBank is the first manually annotated dataset
for figure and table extraction for scanned ETDs. A YOLOv5-based model, trained on ScanBank, outperforms
existing comparable open-source and freely available baseline methods by a considerable margin.
