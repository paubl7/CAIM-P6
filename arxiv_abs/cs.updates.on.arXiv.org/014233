With the ongoing popularization of online services, the digital document images have been used
in various applications. Meanwhile, there have emerged some deep learning-based text editing
algorithms which alter the textual information of an image . In this work, we present a document forgery
algorithm to edit practical document images. To achieve this goal, the limitations of existing
text editing algorithms towards complicated characters and complex background are addressed
by a set of network design strategies. First, the unnecessary confusion in the supervision data
is avoided by disentangling the textual and background information in the source images. Second,
to capture the structure of some complicated components, the text skeleton is provided as auxiliary
information and the continuity in texture is considered explicitly in the loss function. Third,
the forgery traces induced by the text editing operation are mitigated by some post-processing
operations which consider the distortions from the print-and-scan channel. Quantitative comparisons
of the proposed method and the exiting approach have shown the advantages of our design by reducing
the about 2/3 reconstruction error measured in MSE, improving reconstruction quality measured
in PSNR and in SSIM by 4 dB and 0.21, respectively. Qualitative experiments have confirmed that the
reconstruction results of the proposed method are visually better than the existing approach.
More importantly, we have demonstrated the performance of the proposed document forgery algorithm
under a practical scenario where an attacker is able to alter the textual information in an identity
document using only one sample in the target domain. The forged-and-recaptured samples created
by the proposed text editing attack and recapturing operation have successfully fooled some existing
document authentication systems. 