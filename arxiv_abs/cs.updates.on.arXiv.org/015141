Existing person re-identification methods often have low generalizability, which is mostly due
to the limited availability of large-scale labeled training data. However, labeling large-scale
training data is very expensive and time-consuming. To address this, this paper presents a solution,
called DomainMix, which can learn a person re-identification model from both synthetic and real-world
data, for the first time, completely without human annotations. This way, the proposed method enjoys
the cheap availability of large-scale training data, and benefiting from its scalability and diversity,
the learned model is able to generalize well on unseen domains. Specifically, inspired from a recent
work generating large-scale synthetic data for effective person re-identification training,
in each epoch, the proposed method firstly clusters the unlabeled real-world images and select
the reliable clusters according to three criteria, i.e. independence, compactness, and quantity.
Then, the classification layer is initialized adaptively using the generated features of real-world
images. When training, to address the large domain gap between two domains, a domain-invariant
feature learning method is proposed, which designs an adversarial learning between domain-invariant
feature learning and domain discrimination, and meanwhile learns a discriminative feature for
person re-identification. This way, the domain gap between synthetic and real-world data is much
reduced, and the learned feature is generalizable thanks to the large-scale and diverse training
data. Experimental results show that the proposed annotation-free method is more or less comparable
to the counterpart trained with full human annotations, which is quite promising. In addition,
it achieves the current state of the art on several person re-identification datasets under direct
cross-dataset evaluation. 