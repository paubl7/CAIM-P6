We review state-of-the-art formal methods applied to the emerging field of the verification of
machine learning systems. Formal methods can provide rigorous correctness guarantees on hardware
and software systems. Thanks to the availability of mature tools, their use is well established
in the industry, and in particular to check safety-critical applications as they undergo a stringent
certification process. As machine learning is becoming more popular, machine-learned components
are now considered for inclusion in critical systems. This raises the question of their safety and
their verification. Yet, established formal methods are limited to classic, i.e. non machine-learned
software. Applying formal methods to verify systems that include machine learning has only been
considered recently and poses novel challenges in soundness, precision, and scalability. We first
recall established formal methods and their current use in an exemplar safety-critical field,
avionic software, with a focus on abstract interpretation based techniques as they provide a high
level of scalability. This provides a golden standard and sets high expectations for machine learning
verification. We then provide a comprehensive and detailed review of the formal methods developed
so far for machine learning, highlighting their strengths and limitations. The large majority
of them verify trained neural networks and employ either SMT, optimization, or abstract interpretation
techniques. We also discuss methods for support vector machines and decision tree ensembles, as
well as methods targeting training and data preparation, which are critical but often neglected
aspects of machine learning. Finally, we offer perspectives for future research directions towards
the formal verification of machine learning systems. 