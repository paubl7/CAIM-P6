Computing an AUC as a performance measure to compare the quality of different machine learning models
is one of the final steps of many research projects. Many of these methods are trained on privacy-sensitive
data and there are several different approaches like $\epsilon$-differential privacy, federated
machine learning and methods based on cryptographic approaches if the datasets cannot be shared
or evaluated jointly at one place. In this setting, it can also be a problem to compute the global performance
measure like an AUC, since the labels might also contain privacy-sensitive information. There
have been approaches based on $\epsilon$-differential privacy to deal with this problem, but to
the best of our knowledge, no exact privacy preserving solution has been introduced. In this paper,
we propose an MPC-based framework, called \fw{}, with private merging of sorted lists and novel
methods for comparing two secret-shared values, selecting between two secret-shared values,
converting the modulus, and performing division to compute the exact AUC as one could obtain on the
pooled original test samples. With \fw{} computation of the exact area under precision-recall
curve and receiver operating characteristic curve is even possible when ties between prediction
confidence values exist. To show the applicability of \fw{}, we use it to evaluate a model trained
to predict acute myeloid leukemia therapy response and we also assess its scalability via experiments
on synthetic data. The experiments show that we efficiently compute exactly the same AUC with both
evaluation metrics in a privacy preserving manner as one can obtain on the pooled test samples in
the plaintext domain. Our solution provides security against semi-honest corruption of at most
one of the servers performing the secure computation. 