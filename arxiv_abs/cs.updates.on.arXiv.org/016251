Background: The quantitative analysis of microscope videos often requires instance segmentation
and tracking of cellular and subcellular objects. The traditional method consists of two stages:
(1) performing instance object segmentation of each frame, and (2) associating objects frame-by-frame.
Recently, pixel-embedding-based deep learning approaches these two steps simultaneously as
a single stage holistic solution. In computer vision, annotated training data with consistent
segmentation and tracking is resource intensive, the severity of which is multiplied in microscopy
imaging due to (1) dense objects (e.g., overlapping or touching), and (2) high dynamics (e.g., irregular
motion and mitosis). Adversarial simulations have provided successful solutions to alleviate
the lack of such annotations in dynamics scenes in computer vision, such as using simulated environments
(e.g., computer games) to train real-world self-driving systems. Methods: In this paper, we propose
an annotation-free synthetic instance segmentation and tracking (ASIST) method with adversarial
simulation and single-stage pixel-embedding based learning. Contribution: The contribution
of this paper is three-fold: (1) the proposed method aggregates adversarial simulations and single-stage
pixel-embedding based deep learning; (2) the method is assessed with both the cellular (i.e., HeLa
cells) and subcellular (i.e., microvilli) objects; and (3) to the best of our knowledge, this is
the first study to explore annotation-free instance segmentation and tracking study for microscope
videos. Results: The ASIST method achieved an important step forward, when compared with fully
supervised approaches: ASIST shows 7% to 11% higher segmentation, detection and tracking performance
on microvilli relative to fully supervised methods, and comparable performance on Hela cell videos.
