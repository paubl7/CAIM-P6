This paper contributes to the study of PUFs vulnerability against modeling attacks by evaluating
the security of XOR BR PUFs, XOR TBR PUFs, and obfuscated architectures of XOR BR PUF using a simplified
mathematical model and deep learning (DL) techniques. Obtained results show that DL modeling attacks
could easily break the security of 4-input XOR BR PUFs and 4-input XOR TBR PUFs with modeling accuracy
$\sim$ 99%. Similar attacks were executed using single-layer neural networks (NN) and support
vector machines (SVM) with polynomial kernel and the obtained results showed that single NNs failed
to break the PUF security. Furthermore, SVM results confirmed the same modeling accuracy reported
in previous research ($\sim$ 50%). For the first time, this research empirically shows that DL networks
can be used as powerful modeling techniques against these complex PUF architectures for which previous
conventional machine learning techniques had failed. Furthermore, a detailed scalability analysis
is conducted on the DL networks with respect to PUFs' stage size and complexity. The analysis shows
that the number of layers and hidden neurons inside every layer has a linear relationship with PUFs'
stage size, which agrees with the theoretical findings in deep learning. Consequently, A new obfuscated
architecture is introduced as a first step to counter DL modeling attacks and it showed significant
resistance against such attacks (16% - 40% less accuracy). This research provides an important
step towards prioritizing the efforts to introduce new PUF architectures that are more secure and
invulnerable to modeling attacks. Moreover, it triggers future discussions on the removal of influential
bits and the level of obfuscation needed to confirm that a specific PUF architecture is resistant
against powerful DL modeling attacks. 