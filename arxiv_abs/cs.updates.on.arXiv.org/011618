Leo Tolstoy opened his monumental novel Anna Karenina with the now famous words: Happy families
are all alike; every unhappy family is unhappy in its own way A similar notion also applies to mathematical
spaces: Every flat space is alike; every unflat space is unflat in its own way. However, rather than
being a source of unhappiness, we will show that the diversity of non-flat spaces provides a rich
area of study. The genesis of the so-called big data era and the proliferation of social and scientific
databases of increasing size has led to a need for algorithms that can efficiently process, analyze
and, even generate high dimensional data. However, the curse of dimensionality leads to the fact
that many classical approaches do not scale well with respect to the size of these problems. One technique
to avoid some of these ill-effects is to exploit the geometric structure of coherent data. In this
thesis, we will explore geometric methods for shape processing and data analysis. More specifically,
we will study techniques for representing manifolds and signals supported on them through a variety
of mathematical tools including, but not limited to, computational differential geometry, variational
PDE modeling, and deep learning. First, we will explore non-isometric shape matching through variational
modeling. Next, we will use ideas from parallel transport on manifolds to generalize convolution
and convolutional neural networks to deformable manifolds. Finally, we conclude by proposing
a novel auto-regressive model for capturing the intrinsic geometry and topology of data. Throughout
this work, we will use the idea of computing correspondences as a though-line to both motivate our
work and analyze our results. 