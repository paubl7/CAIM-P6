Federated learning (FL) has recently emerged as a promising technology to enable artificial intelligence
(AI) at the network edge, where distributed mobile devices collaboratively train a shared AI model
under the coordination of an edge server. To significantly improve the communication efficiency
of FL, over-the-air computation allows a large number of mobile devices to concurrently upload
their local models by exploiting the superposition property of wireless multi-access channels.
Due to wireless channel fading, the model aggregation error at the edge server is dominated by the
weakest channel among all devices, causing severe straggler issues. In this paper, we propose a
relay-assisted cooperative FL scheme to effectively address the straggler issue. In particular,
we deploy multiple half-duplex relays to cooperatively assist the devices in uploading the local
model updates to the edge server. The nature of the over-the-air computation poses system objectives
and constraints that are distinct from those in traditional relay communication systems. Moreover,
the strong coupling between the design variables renders the optimization of such a system challenging.
To tackle the issue, we propose an alternating-optimization-based algorithm to optimize the transceiver
and relay operation with low complexity. Then, we analyze the model aggregation error in a single-relay
case and show that our relay-assisted scheme achieves a smaller error than the one without relays
provided that the relay transmit power and the relay channel gains are sufficiently large. The analysis
provides critical insights on relay deployment in the implementation of cooperative FL. Extensive
numerical results show that our design achieves faster convergence compared with state-of-the-art
schemes. 