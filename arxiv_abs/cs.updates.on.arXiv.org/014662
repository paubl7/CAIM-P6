The COVID-19 pandemic has impacted on every human activity and, because of the urgency of finding
the proper responses to such an unprecedented emergency, it generated a diffused societal debate.
The online version of this discussion was not exempted by the presence of d/misinformation campaigns,
but differently from what already witnessed in other debates, the COVID-19 -- intentional or not
-- flow of false information put at severe risk the public health, reducing the effectiveness of
governments' countermeasures. In the present manuscript, we study the effective impact of misinformation
in the Italian societal debate on Twitter during the pandemic, focusing on the various discursive
communities. In order to extract the discursive communities, we focus on verified users, i.e. accounts
whose identity is officially certified by Twitter. We thus infer the various discursive communities
based on how verified users are perceived by standard ones: if two verified accounts are considered
as similar by non unverified ones, we link them in the network of certified accounts. We first observe
that, beside being a mostly scientific subject, the COVID-19 discussion show a clear division in
what results to be different political groups. At this point, by using a commonly available fact-checking
software (NewsGuard), we assess the reputation of the pieces of news exchanged. We filter the network
of retweets (i.e. users re-broadcasting the same elementary piece of information, or tweet) from
random noise and check the presence of messages displaying an url. The impact of misinformation
posts reaches the 22.1% in the right and center-right wing community and its contribution is even
stronger in absolute numbers, due to the activity of this group: 96% of all non reputable urls shared
by political groups come from this community. 