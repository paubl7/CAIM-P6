Deep Learning has become an attractive approach towards various data-based problems of theoretical
physics in the past decade. Its protagonists, the deep neural networks (DNNs), are capable of making
accurate predictions for data of arbitrarily high complexity. A well-known issue most DNNs share
is their lack of interpretability. In order to explain their behavior and extract physical laws
they have discovered during training, a suitable interpretation method has, therefore, to be applied
post-hoc. Due to its simplicity and ubiquity in quantum physics, we decide to present a rather general
interpretation method in the context of two-body scattering: We find a one-to-one correspondence
between the $n^\text{th}$-order Born approximation and the $n^\text{th}$-order Taylor approximation
of deep multilayer perceptrons (MLPs), that predict S-wave scattering lengths $a_0$ for discretized,
attractive potentials of finite range. This defines a perturbation theory for MLPs similarily
to Born approximations defining a perturbation theory for $a_0$. In the case of shallow potentials,
lower-order approximations, that can be argued to be local interpretations of respective MLPs,
reliably reproduce $a_0$. As deep MLPs are highly nested functions, the computation of higher-order
partial derivatives, which is substantial for a Taylor approximation, is an effortful endeavour.
By introducing quantities we refer to as propagators and vertices and that depend on the MLP's weights
and biases, we establish a graph-theoretical approach towards partial derivatives and local interpretability.
Similar to Feynman rules in quantum field theories, we find rules that systematically assign diagrams
consisting of propagators and vertices to the corresponding order of the MLP perturbation theory.
