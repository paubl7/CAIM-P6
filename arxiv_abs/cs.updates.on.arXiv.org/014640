360-degree/omnidirectional images (OIs) have achieved remarkable attentions due to the increasing
applications of virtual reality (VR). Compared to conventional 2D images, OIs can provide more
immersive experience to consumers, benefitting from the higher resolution and plentiful field
of views (FoVs). Moreover, observing OIs is usually in the head mounted display (HMD) without references.
Therefore, an efficient blind quality assessment method, which is specifically designed for 360-degree
images, is urgently desired. In this paper, motivated by the characteristics of the human visual
system (HVS) and the viewing process of VR visual contents, we propose a novel and effective no-reference
omnidirectional image quality assessment (NR OIQA) algorithm by Multi-Frequency Information
and Local-Global Naturalness (MFILGN). Specifically, inspired by the frequency-dependent property
of visual cortex, we first decompose the projected equirectangular projection (ERP) maps into
wavelet subbands. Then, the entropy intensities of low and high frequency subbands are exploited
to measure the multi-frequency information of OIs. Besides, except for considering the global
naturalness of ERP maps, owing to the browsed FoVs, we extract the natural scene statistics features
from each viewport image as the measure of local naturalness. With the proposed multi-frequency
information measurement and local-global naturalness measurement, we utilize support vector
regression as the final image quality regressor to train the quality evaluation model from visual
quality-related features to human ratings. To our knowledge, the proposed model is the first no-reference
quality assessment method for 360-degreee images that combines multi-frequency information
and image naturalness. Experimental results on two publicly available OIQA databases demonstrate
that our proposed MFILGN outperforms state-of-the-art approaches. 