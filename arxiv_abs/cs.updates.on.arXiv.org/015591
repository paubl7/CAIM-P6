Analogy-making is at the core of human intelligence and creativity with applications to such diverse
tasks as commonsense reasoning, learning, language acquisition, and story telling. This paper
contributes to the foundations of artificial general intelligence by introducing from first principles
an abstract algebraic framework of analogical proportions of the form `$a$ is to $b$ what $c$ is to
$d$' in the general setting of universal algebra. This enables us to compare mathematical objects
possibly across different domains in a uniform way which is crucial for AI-systems. The main idea
is to define solutions to analogical equations in terms of maximal sets of algebraic justifications,
which amounts to deriving abstract terms of concrete elements from a `known' source domain which
can then be instantiated in an `unknown' target domain to obtain analogous elements. It turns out
that our notion of analogical proportions has appealing mathematical properties. For example,
we show that analogical proportions preserve functional dependencies across different domains,
which is desirable. We extensively compare our framework with two prominent and recently introduced
frameworks of analogical proportions from the literature in the concrete domains of sets, numbers,
and words, and we show that in each case we either disagree with the notion from the literature justified
by some plausible counter-examples or we can show that our model yields strictly more reasonable
solutions. This provides evidence for its applicability. In a broader sense, this paper is a first
step towards a theory of analogical reasoning and learning systems with potential applications
to fundamental AI-problems like commonsense reasoning and computational learning and creativity.
