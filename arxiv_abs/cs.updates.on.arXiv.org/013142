There's a long tradition of research using computational intelligence (methods from artificial
intelligence (AI) and machine learning (ML)), to automatically discover, implement, and fine-tune
strategies for autonomous adaptive automated trading in financial markets, with a sequence of
research papers on this topic published at AI conferences such as IJCAI and in journals such as Artificial
Intelligence: we show here that this strand of research has taken a number of methodological mis-steps
and that actually some of the reportedly best-performing public-domain AI/ML trading strategies
can routinely be out-performed by extremely simple trading strategies that involve no AI or ML at
all. The results that we highlight here could easily have been revealed at the time that the relevant
key papers were published, more than a decade ago, but the accepted methodology at the time of those
publications involved a somewhat minimal approach to experimental evaluation of trader-agents,
making claims on the basis of a few thousand test-sessions of the trader-agent in a small number of
market scenarios. In this paper we present results from exhaustive testing over wide ranges of parameter
values, using parallel cloud-computing facilities, where we conduct millions of tests and thereby
create much richer data from which firmer conclusions can be drawn. We show that the best public-domain
AI/ML traders in the published literature can be routinely outperformed by a "sub-zero-intelligence"
trading strategy that at face value appears to be so simple as to be financially ruinous, but which
interacts with the market in such a way that in practice it is more profitable than the well-known
AI/ML strategies from the research literature. That such a simple strategy can outperform established
AI/ML-based strategies is a sign that perhaps the AI/ML trading strategies were good answers to
the wrong question. 