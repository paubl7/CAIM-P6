Automatic hate speech detection in online social networks is an important open problem in Natural
Language Processing (NLP). Hate speech is a multidimensional issue, strongly dependant on language
and cultural factors. Despite its relevance, research on this topic has been almost exclusively
devoted to English. Most supervised learning resources, such as labeled datasets and NLP tools,
have been created for this same language. Considering that a large portion of users worldwide speak
in languages other than English, there is an important need for creating efficient approaches for
multilingual hate speech detection. In this work we propose to address the problem of multilingual
hate speech detection from the perspective of transfer learning. Our goal is to determine if knowledge
from one particular language can be used to classify other language, and to determine effective
ways to achieve this. We propose a hate specific data representation and evaluate its effectiveness
against general-purpose universal representations most of which, unlike our proposed model,
have been trained on massive amounts of data. We focus on a cross-lingual setting, in which one needs
to classify hate speech in one language without having access to any labeled data for that language.
We show that the use of our simple yet specific multilingual hate representations improves classification
results. We explain this with a qualitative analysis showing that our specific representation
is able to capture some common patterns in how hate speech presents itself in different languages.
Our proposal constitutes, to the best of our knowledge, the first attempt for constructing multilingual
specific-task representations. Despite its simplicity, our model outperformed the previous
approaches for most of the experimental setups. Our findings can orient future solutions toward
the use of domain-specific representations. 