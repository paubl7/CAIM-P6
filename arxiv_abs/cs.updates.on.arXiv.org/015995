The deep learning algorithm has achieved great success in the field of computer vision, but some
studies have pointed out that the deep learning model is vulnerable to attacks adversarial examples
and makes false decisions. This challenges the further development of deep learning, and urges
researchers to pay more attention to the relationship between adversarial examples attacks and
deep learning security. This work focuses on adversarial examples, optimizes the generation of
adversarial examples from the view of adversarial robustness, takes the perturbations added in
adversarial examples as the optimization parameter. We propose RWR-NM-PGD attack algorithm based
on random warm restart mechanism and improved Nesterov momentum from the view of gradient optimization.
The algorithm introduces improved Nesterov momentum, using its characteristics of accelerating
convergence and improving gradient update direction in optimization algorithm to accelerate
the generation of adversarial examples. In addition, the random warm restart mechanism is used
for optimization, and the projected gradient descent algorithm is used to limit the range of the
generated perturbations in each warm restart, which can obtain better attack effect. Experiments
on two public datasets show that the algorithm proposed in this work can improve the success rate
of attacking deep learning models without extra time cost. Compared with the benchmark attack method,
the algorithm proposed in this work can achieve better attack success rate for both normal training
model and defense model. Our method has average attack success rate of 46.3077%, which is 27.19%
higher than I-FGSM and 9.27% higher than PGD. The attack results in 13 defense models show that the
attack algorithm proposed in this work is superior to the benchmark algorithm in attack universality
and transferability. 