Purpose: To stabilize the NLPContributionGraph scheme for the surface structuring of contributions
information in Natural Language Processing (NLP) scholarly articles via a two-stage annotation
methodology: first stage - to define the scheme; and second stage - to stabilize the graphing model.
Approach: Re-annotate, a second time, the contributions-pertinent information across 50 prior-annotated
NLP scholarly articles in terms of a data pipeline comprising: contribution-centered sentences,
phrases, and triples. To this end specifically, care was taken in the second annotation stage to
reduce annotation noise while formulating the guidelines for our proposed novel NLP contributions
structuring scheme. Findings: The application of NLPContributionGraph on the 50 articles resulted
in finally in a dataset of 900 contribution-focused sentences, 4,702 contribution-information-centered
phrases, and 2,980 surface-structured triples. The intra-annotation agreement between the first
and second stages, in terms of F1, was 67.92% for sentences, 41.82% for phrases, and 22.31% for triples
indicating that with an increased granularity of the information, the annotation decision variance
is greater. Practical Implications: Demonstrate NLPContributionGraph data integrated in the
Open Research Knowledge Graph (ORKG), a next-generation KG-based digital library with compute
enabled over structured scholarly knowledge, as a viable aid to assist researchers in their day-to-day
tasks. Value: NLPContributionGraph is a novel scheme to obtain research contribution-centered
graphs from NLP articles which to the best of our knowledge does not exist in the community. And our
quantitative evaluations over the two-stage annotation tasks offer insights into task difficulty.
