A plethora of research in the literature shows how human eye fixation pattern varies depending on
different factors, including genetics, age, social functioning, cognitive functioning, and
so on. Analysis of these variations in visual attention has already elicited two potential research
avenues: 1) determining the physiological or psychological state of the subject and 2) predicting
the tasks associated with the act of viewing from the recorded eye-fixation data. To this end, this
paper proposes a visual saliency based novel feature extraction method for automatic and quantitative
classification of eye-tracking data, which is applicable to both of the research directions. Instead
of directly extracting features from the fixation data, this method employs several well-known
computational models of visual attention to predict eye fixation locations as saliency maps. Comparing
the saliency amplitudes, similarity and dissimilarity of saliency maps with the corresponding
eye fixations maps gives an extra dimension of information which is effectively utilized to generate
discriminative features to classify the eye-tracking data. Extensive experimentation using
Saliency4ASD, Age Prediction, and Visual Perceptual Task dataset show that our saliency-based
feature can achieve superior performance, outperforming the previous state-of-the-art methods
by a considerable margin. Moreover, unlike the existing application-specific solutions, our
method demonstrates performance improvement across three distinct problems from the real-life
domain: Autism Spectrum Disorder screening, toddler age prediction, and human visual perceptual
task classification, providing a general paradigm that utilizes the extra-information inherent
in saliency maps for a more accurate classification. 