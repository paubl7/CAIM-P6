This paper presents an approach for low-cost simulation modeling for application development
for wireless sensor networks. Computational complexity of simulating wireless sensor networks
can be very high and as such must be carefully managed. Application-level code prototyping with
reasonable accuracy and fidelity can be accomplished through simulation that models only the effects
of the wireless and distributed computations which materialize mainly as delay and drop for the
messages being exchanged among the motes. This approach employs the abstraction that all physical
or communication and protocol level operations can be represented in terms of their effects as message
delay and drop at the application level for a wireless sensor network. This study proposes that idea
of empirical modeling of delay and drop and employing those models to affect the reception times
of wirelessly communicated messages. It further proposes the delay and drop to be modeled as random
variables with probability distributions empirically approximated based on the data reported
in the literature. The proposed approach is demonstrated through development of a neural network
application with neurons distributed across the motes of a wireless sensor network. Delay and drop
are incorporated into wireless communications, which carry neuron output values among motes.
A set of classification data sets from the Machine Learning Repository are employed to demonstrate
the performance of the proposed system in a comparative context with the similar studies in the literature.
Results and findings indicate that the proposed approach of abstracting wireless sensor network
operation in terms of message delay and drop at the application level is feasible to facilitate development
of applications with competitive performance profiles while minimizing the spatio-temporal
cost of simulation. 