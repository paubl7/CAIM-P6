Rain is a common phenomenon in nature and an essential factor for many deep neural network (DNN) based
perception systems. Rain can often post inevitable threats that must be carefully addressed especially
in the context of safety and security-sensitive scenarios (e.g., autonomous driving). Therefore,
a comprehensive investigation of the potential risks of the rain to a DNN is of great importance.
Unfortunately, in practice, it is often rather difficult to collect or synthesize rainy images
that can represent all raining situations that possibly occur in the real world. To this end, in this
paper, we start from a new perspective and propose to combine two totally different studies, i.e.,
rainy image synthesis and adversarial attack. We present an adversarial rain attack, with which
we could simulate various rainy situations with the guidance of deployed DNNs and reveal the potential
threat factors that can be brought by rain, helping to develop more rain-robust DNNs. In particular,
we propose a factor-aware rain generation that simulates rain steaks according to the camera exposure
process and models the learnable rain factors for adversarial attack. With this generator, we further
propose the adversarial rain attack against the image classification and object detection, where
the rain factors are guided by the various DNNs. As a result, it enables to comprehensively study
the impacts of the rain factors to DNNs. Our largescale evaluation on three datasets, i.e., NeurIPS'17
DEV, MS COCO and KITTI, demonstrates that our synthesized rainy images can not only present visually
realistic appearances, but also exhibit strong adversarial capability, which builds the foundation
for further rain-robust perception studies. 