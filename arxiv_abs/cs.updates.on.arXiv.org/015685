This paper studies the transmit beamforming in a downlink integrated sensing and communication
(ISAC) system, where a base station (BS) equipped with a uniform linear array (ULA) sends combined
information-bearing and dedicated radar signals to simultaneously perform downlink multiuser
communication and radar target sensing. Under this setup, we maximize the radar sensing performance
(in terms of minimizing the beampattern matching errors or maximizing the minimum beampattern
gains), subject to the communication users' minimum signal-to-interference-plus-noise ratio
(SINR) requirements and the BS's transmit power constraints. In particular, we consider two types
of communication receivers, namely Type-I and Type-II receivers, which do not have and do have the
capability of cancelling the interference from the {\emph{a-priori}} known dedicated radar signals,
respectively. Under both Type-I and Type-II receivers, the beampattern matching and minimum beampattern
gain maximization problems are globally optimally solved via applying the semidefinite relaxation
(SDR) technique together with the rigorous proof of the tightness of SDR for both Type-I and Type-II
receivers under the two design criteria. It is shown that at the optimality, dedicated radar signals
are not required with Type-I receivers under some specific conditions, while dedicated radar signals
are always needed to enhance the performance with Type-II receivers. Numerical results show that
the minimum beampattern gain maximization leads to significantly higher beampattern gains at
the worst-case sensing angles with a much lower computational complexity than the beampattern
matching design. It is also shown that by exploiting the capability of canceling the interference
caused by the radar signals, the case with Type-II receivers results in better sensing performance
than that with Type-I receivers and other conventional designs. 