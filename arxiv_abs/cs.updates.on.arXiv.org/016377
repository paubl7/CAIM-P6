In the past decade, there has been much discussion about the issue of biased reporting in clinical
research. Despite this attention, there have been limited tools developed for the systematic assessment
of qualitative statements made in clinical research, with most studies assessing qualitative
statements relying on the use of manual expert raters, which limits their size. Also, previous attempts
to develop larger scale tools, such as those using natural language processing, were limited by
both their accuracy and the number of categories used for the classification of their findings.
With these limitations in mind, this study's goal was to develop a classification algorithm that
was both suitably accurate and finely grained to be applied on a large scale for assessing the qualitative
sentiment expressed in clinical trial abstracts. Additionally, this study seeks to compare the
performance of the proposed algorithm, GAN-BioBERT, to previous studies as well as to expert manual
rating of clinical trial abstracts. This study develops a three-class sentiment classification
algorithm for clinical trial abstracts using a semi-supervised natural language process model
based on the Bidirectional Encoder Representation from Transformers (BERT) model, from a series
of clinical trial abstracts annotated by a group of experts in academic medicine. Results: The use
of this algorithm was found to have a classification accuracy of 91.3%, with a macro F1-Score of 0.92,
which is a significant improvement in accuracy when compared to previous methods and expert ratings,
while also making the sentiment classification finer grained than previous studies. The proposed
algorithm, GAN-BioBERT, is a suitable classification model for the large-scale assessment of
qualitative statements in clinical trial literature, providing an accurate, reproducible tool
for the large-scale study of clinical publication trends. 