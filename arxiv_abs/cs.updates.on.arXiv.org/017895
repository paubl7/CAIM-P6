This thesis investigates the controllability of deep learning-based, end-to-end, generative
dialogue systems in both task-oriented and chit-chat scenarios. In particular, we study the different
aspects of controlling generative dialogue systems, including controlling styles and topics
and continuously adding and combining dialogue skills. In the three decades since the first dialogue
system was commercialized, the basic architecture of such systems has remained substantially
unchanged, consisting of four pipelined basic components, namely, natural language understanding
(NLU), dialogue state tracking (DST), a dialogue manager (DM) and natural language generation
(NLG). The dialogue manager, which is the critical component of the modularized system, controls
the response content and style. This module is usually programmed by rules and is designed to be highly
controllable and easily extendable. With the emergence of powerful "deep learning" architectures,
end-to-end generative dialogue systems have been proposed to optimize overall system performance
and simplify training. However, these systems cannot be easily controlled and extended as the modularized
dialogue manager can. This is because a single neural system is used, which is usually a large pre-trained
language model (e.g., GPT-2), and thus it is hard to surgically change desirable attributes (e.g.,
style, topics, etc.). More importantly, uncontrollable dialogue systems can generate offensive
and even toxic responses. Therefore, in this thesis, we study controllable methods for end-to-end
generative dialogue systems in task-oriented and chit-chat scenarios. Throughout the chapters,
we describe 1) how to control the style and topics of chit-chat models, 2) how to continuously control
and extend task-oriented dialogue systems, and 3) how to compose and control multi-skill dialogue
models. 