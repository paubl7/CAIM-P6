Accurate and realistic simulation of high-dimensional medical images has become an important
research area relevant to many AI-enabled healthcare applications. However, current state-of-the-art
approaches lack the ability to produce satisfactory high-resolution and accurate subject-specific
images. In this work, we present a deep learning framework, namely 4D-Degenerative Adversarial
NeuroImage Net (4D-DANI-Net), to generate high-resolution, longitudinal MRI scans that mimic
subject-specific neurodegeneration in ageing and dementia. 4D-DANI-Net is a modular framework
based on adversarial training and a set of novel spatiotemporal, biologically-informed constraints.
To ensure efficient training and overcome memory limitations affecting such high-dimensional
problems, we rely on three key technological advances: i) a new 3D training consistency mechanism
called Profile Weight Functions (PWFs), ii) a 3D super-resolution module and iii) a transfer learning
strategy to fine-tune the system for a given individual. To evaluate our approach, we trained the
framework on 9852 T1-weighted MRI scans from 876 participants in the Alzheimer's Disease Neuroimaging
Initiative dataset and held out a separate test set of 1283 MRI scans from 170 participants for quantitative
and qualitative assessment of the personalised time series of synthetic images. We performed three
evaluations: i) image quality assessment; ii) quantifying the accuracy of regional brain volumes
over and above benchmark models; and iii) quantifying visual perception of the synthetic images
by medical experts. Overall, both quantitative and qualitative results show that 4D-DANI-Net
produces realistic, low-artefact, personalised time series of synthetic T1 MRI that outperforms
benchmark models. 