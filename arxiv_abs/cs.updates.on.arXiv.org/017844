Spatiotemporal (ST) image data are increasingly common and often high-dimensional (high-D).
Modeling ST data can be a challenge due to the plethora of independent and interacting processes
which may or may not contribute to the measurements. Characterization can be considered the complement
to modeling by helping guide assumptions about generative processes and their representation
in the data. Dimensionality reduction (DR) is a frequently implemented type of characterization
designed to mitigate the "curse of dimensionality" on high-D signals. For decades, Principal Component
(PC) and Empirical Orthogonal Function (EOF) analysis has been used as a linear, invertible approach
to DR and ST analysis. Recent years have seen the additional development of a suite of nonlinear DR
algorithms, frequently categorized as "manifold learning". Here, we explore the idea of joint
characterization of ST data manifolds using PCs/EOFs alongside two nonlinear DR approaches: Laplacian
Eigenmaps (LE) and t-distributed stochastic neighbor embedding (t-SNE). Starting with a synthetic
example and progressing to global, regional, and field scale ST datasets spanning roughly 5 orders
of magnitude in space and 2 in time, we show these three DR approaches can yield complementary information
about ST manifold topology. Compared to the relatively diffuse TFS produced by PCs/EOFs, the nonlinear
approaches yield more compact manifolds with decreased ambiguity in temporal endmembers (LE)
and/or in spatiotemporal clustering (t-SNE). These properties are compensated by the greater
interpretability, significantly lower computational demand and diminished sensitivity to spatial
aliasing for PCs/EOFs than LE or t-SNE. Taken together, we find joint characterization using the
three complementary DR approaches capable of greater insight into generative ST processes than
possible using any single approach alone. 