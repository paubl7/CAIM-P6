The success of deep learning in recent years have led to a significant increase in interest and prevalence
for its adoption to tackle financial services tasks. One particular question that often arises
as a barrier to adopting deep learning for financial services is whether the developed financial
deep learning models are fair in their predictions, particularly in light of strong governance
and regulatory compliance requirements in the financial services industry. A fundamental aspect
of fairness that has not been explored in financial deep learning is the concept of trust, whose variations
may point to an egocentric view of fairness and thus provide insights into the fairness of models.
In this study we explore the feasibility and utility of a multi-scale trust quantification strategy
to gain insights into the fairness of a financial deep learning model, particularly under different
scenarios at different scales. More specifically, we conduct multi-scale trust quantification
on a deep neural network for the purpose of credit card default prediction to study: 1) the overall
trustworthiness of the model 2) the trust level under all possible prediction-truth relationships,
3) the trust level across the spectrum of possible predictions, 4) the trust level across different
demographic groups (e.g., age, gender, and education), and 5) distribution of overall trust for
an individual prediction scenario. The insights for this proof-of-concept study demonstrate
that such a multi-scale trust quantification strategy may be helpful for data scientists and regulators
in financial services as part of the verification and certification of financial deep learning
solutions to gain insights into fairness and trust of these solutions. 