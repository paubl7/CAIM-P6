Current neuroimaging techniques provide paths to investigate the structure and function of the
brain in vivo and have made great advances in understanding Alzheimer's disease (AD). However,
the group-level analyses prevalently used for investigation and understanding of the disease
are not applicable for diagnosis of individuals. More recently, deep learning, which can efficiently
analyze large-scale complex patterns in 3D brain images, has helped pave the way for computer-aided
individual diagnosis by providing accurate and automated disease classification. Great progress
has been made in classifying AD with deep learning models developed upon increasingly available
structural MRI data. The lack of scale-matched functional neuroimaging data prevents such models
from being further improved by observing functional changes in pathophysiology. Here we propose
a potential solution by first learning a structural-to-functional transformation in brain MRI,
and further synthesizing spatially matched functional images from large-scale structural scans.
We evaluated our approach by building computational models to discriminate patients with AD from
healthy normal subjects and demonstrated a performance boost after combining the structural and
synthesized functional brain images into the same model. Furthermore, our regional analyses identified
the temporal lobe to be the most predictive structural-region and the parieto-occipital lobe to
be the most predictive functional-region of our model, which are both in concordance with previous
group-level neuroimaging findings. Together, we demonstrate the potential of deep learning with
large-scale structural and synthesized functional MRI to impact AD classification and to identify
AD's neuroimaging signatures. 