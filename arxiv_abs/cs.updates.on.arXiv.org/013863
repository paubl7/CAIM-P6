Although pain is frequent in old age, older adults are often undertreated for pain. This is especially
the case for long-term care residents with moderate to severe dementia who cannot report their pain
because of cognitive impairments that accompany dementia. Nursing staff acknowledge the challenges
of effectively recognizing and managing pain in long-term care facilities due to lack of human resources
and, sometimes, expertise to use validated pain assessment approaches on a regular basis. Vision-based
ambient monitoring will allow for frequent automated assessments so care staff could be automatically
notified when signs of pain are displayed. However, existing computer vision techniques for pain
detection are not validated on faces of older adults or people with dementia, and this population
is not represented in existing facial expression datasets of pain. We present the first fully automated
vision-based technique validated on a dementia cohort. Our contributions are threefold. First,
we develop a deep learning-based computer vision system for detecting painful facial expressions
on a video dataset that is collected unobtrusively from older adult participants with and without
dementia. Second, we introduce a pairwise comparative inference method that calibrates to each
person and is sensitive to changes in facial expression while using training data more efficiently
than sequence models. Third, we introduce a fast contrastive training method that improves cross-dataset
performance. Our pain estimation model outperforms baselines by a wide margin, especially when
evaluated on faces of people with dementia. Pre-trained model and demo code available at https://github.com/TaatiTeam/pain_detection_demo
