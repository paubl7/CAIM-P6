Existing deep learning methods for diagnosis of gastric cancer commonly use convolutional neural
network. Recently, the Visual Transformer has attracted great attention because of its performance
and efficiency, but its applications are mostly in the field of computer vision. In this paper, a
multi-scale visual transformer model, referred to as GasHis-Transformer, is proposed for Gastric
Histopathological Image Classification (GHIC), which enables the automatic classification
of microscopic gastric images into abnormal and normal cases. The GasHis-Transformer model consists
of two key modules: A global information module and a local information module to extract histopathological
features effectively. In our experiments, a public hematoxylin and eosin (H&E) stained gastric
histopathological dataset with 280 abnormal and normal images are divided into training, validation
and test sets by a ratio of 1 : 1 : 2. The GasHis-Transformer model is applied to estimate precision,
recall, F1-score and accuracy on the test set of gastric histopathological dataset as 98.0%, 100.0%,
96.0% and 98.0%, respectively. Furthermore, a critical study is conducted to evaluate the robustness
of GasHis-Transformer, where ten different noises including four adversarial attack and six conventional
image noises are added. In addition, a clinically meaningful study is executed to test the gastrointestinal
cancer identification performance of GasHis-Transformer with 620 abnormal images and achieves
96.8% accuracy. Finally, a comparative study is performed to test the generalizability with both
H&E and immunohistochemical stained images on a lymphoma image dataset and a breast cancer dataset,
producing comparable F1-scores (85.6% and 82.8%) and accuracies (83.9% and 89.4%), respectively.
In conclusion, GasHisTransformer demonstrates high classification performance and shows its
significant potential in the GHIC task. 