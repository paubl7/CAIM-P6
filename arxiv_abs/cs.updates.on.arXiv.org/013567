When diagnosing the brain tumor, doctors usually make a diagnosis by observing multimodal brain
images from the axial view, the coronal view and the sagittal view, respectively. And then they make
a comprehensive decision to confirm the brain tumor based on the information obtained from multi-views.
Inspired by this diagnosing process and in order to further utilize the 3D information hidden in
the dataset, this paper proposes a multi-view dynamic fusion framework to improve the performance
of brain tumor segmentation. The proposed framework consists of 1) a multi-view deep neural network
architecture, which represents multi learning networks for segmenting the brain tumor from different
views and each deep neural network corresponds to multi-modal brain images from one single view
and 2) the dynamic decision fusion method, which is mainly used to fuse segmentation results from
multi-views as an integrate one and two different fusion methods, the voting method and the weighted
averaging method, have been adopted to evaluate the fusing process. Moreover, the multi-view fusion
loss, which consists of the segmentation loss, the transition loss and the decision loss, is proposed
to facilitate the training process of multi-view learning networks so as to keep the consistency
of appearance and space, not only in the process of fusing segmentation results, but also in the process
of training the learning network. \par By evaluating the proposed framework on BRATS 2015 and BRATS
2018, it can be found that the fusion results from multi-views achieve a better performance than
the segmentation result from the single view and the effectiveness of proposed multi-view fusion
loss has also been proved. Moreover, the proposed framework achieves a better segmentation performance
and a higher efficiency compared to other counterpart methods. 