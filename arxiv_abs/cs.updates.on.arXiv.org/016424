Cardiac auscultation is an essential point-of-care method used for the early diagnosis of heart
diseases. Automatic analysis of heart sounds for abnormality detection is faced with the challenges
of additive noise and sensor-dependent degradation. This paper aims to develop methods to address
the cardiac abnormality detection problem when both types of distortions are present in the cardiac
auscultation sound. We first mathematically analyze the effect of additive and convolutional
noise on short-term filterbank-based features and a Convolutional Neural Network (CNN) layer.
Based on the analysis, we propose a combination of linear and logarithmic spectrogram-image features.
These 2D features are provided as input to a residual CNN network (ResNet) for heart sound abnormality
detection. Experimental validation is performed on an open-access heart sound abnormality detection
dataset involving noisy recordings obtained from multiple stethoscope sensors. The proposed
method achieves significantly improved results compared to the conventional approaches, with
an area under the ROC (receiver operating characteristics) curve (AUC) of 91.36%, F-1 score of 84.09%,
and Macc (mean of sensitivity and specificity) of 85.08%. We also show that the proposed method shows
the best mean accuracy across different source domains including stethoscope and noise variability,
demonstrating its effectiveness in different recording conditions. The proposed combination
of linear and logarithmic features along with the ResNet classifier effectively minimizes the
impact of background noise and sensor variability for classifying phonocardiogram (PCG) signals.
The proposed method paves the way towards developing computer-aided cardiac auscultation systems
in noisy environments using low-cost stethoscopes. 