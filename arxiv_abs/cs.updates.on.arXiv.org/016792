The growth rate in the amount of biomedical documents is staggering. Unlocking information trapped
in these documents can enable researchers and practitioners to operate confidently in the information
world. Biomedical NER, the task of recognising biomedical names, is usually employed as the first
step of the NLP pipeline. Standard NER models, based on sequence tagging technique, are good at recognising
short entity mentions in the generic domain. However, there are several open challenges of applying
these models to recognise biomedical names: 1) Biomedical names may contain complex inner structure
(discontinuity and overlapping) which cannot be recognised using standard sequence tagging technique;
2) The training of NER models usually requires large amount of labelled data, which are difficult
to obtain in the biomedical domain; and, 3) Commonly used language representation models are pre-trained
on generic data; a domain shift therefore exists between these models and target biomedical data.
To deal with these challenges, we explore several research directions and make the following contributions:
1) we propose a transition-based NER model which can recognise discontinuous mentions; 2) We develop
a cost-effective approach that nominates the suitable pre-training data; and, 3) We design several
data augmentation methods for NER. Our contributions have obvious practical implications, especially
when new biomedical applications are needed. Our proposed data augmentation methods can help the
NER model achieve decent performance, requiring only a small amount of labelled data. Our investigation
regarding selecting pre-training data can improve the model by incorporating language representation
models, which are pre-trained using in-domain data. Finally, our proposed transition-based NER
model can further improve the performance by recognising discontinuous mentions. 