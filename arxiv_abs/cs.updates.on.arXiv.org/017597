Background: Maintaining a healthy diet is vital to avoid health-related issues, e.g., undernutrition,
obesity and many non-communicable diseases. An indispensable part of the health diet is dietary
assessment. Traditional manual recording methods are burdensome and contain substantial biases
and errors. Recent advances in Artificial Intelligence, especially computer vision technologies,
have made it possible to develop automatic dietary assessment solutions, which are more convenient,
less time-consuming and even more accurate to monitor daily food intake. Scope and approach: This
review presents one unified Vision-Based Dietary Assessment (VBDA) framework, which generally
consists of three stages: food image analysis, volume estimation and nutrient derivation. Vision-based
food analysis methods, including food recognition, detection and segmentation, are systematically
summarized, and methods of volume estimation and nutrient derivation are also given. The prosperity
of deep learning makes VBDA gradually move to an end-to-end implementation, which applies food
images to a single network to directly estimate the nutrition. The recently proposed end-to-end
methods are also discussed. We further analyze existing dietary assessment datasets, indicating
that one large-scale benchmark is urgently needed, and finally highlight key challenges and future
trends for VBDA. Key findings and conclusions: After thorough exploration, we find that multi-task
end-to-end deep learning approaches are one important trend of VBDA. Despite considerable research
progress, many challenges remain for VBDA due to the meal complexity. We also provide the latest
ideas for future development of VBDA, e.g., fine-grained food analysis and accurate volume estimation.
This survey aims to encourage researchers to propose more practical solutions for VBDA. 