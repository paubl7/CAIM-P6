The history of AI has included several "waves" of ideas. The first wave, from the mid-1950s to the
1980s, focused on logic and symbolic hand-encoded representations of knowledge, the foundations
of so-called "expert systems". The second wave, starting in the 1990s, focused on statistics and
machine learning, in which, instead of hand-programming rules for behavior, programmers constructed
"statistical learning algorithms" that could be trained on large datasets. In the most recent wave
research in AI has largely focused on deep (i.e., many-layered) neural networks, which are loosely
inspired by the brain and trained by "deep learning" methods. However, while deep neural networks
have led to many successes and new capabilities in computer vision, speech recognition, language
processing, game-playing, and robotics, their potential for broad application remains limited
by several factors. A concerning limitation is that even the most successful of today's AI systems
suffer from brittleness-they can fail in unexpected ways when faced with situations that differ
sufficiently from ones they have been trained on. This lack of robustness also appears in the vulnerability
of AI systems to adversarial attacks, in which an adversary can subtly manipulate data in a way to
guarantee a specific wrong answer or action from an AI system. AI systems also can absorb biases-based
on gender, race, or other factors-from their training data and further magnify these biases in their
subsequent decision-making. Taken together, these various limitations have prevented AI systems
such as automatic medical diagnosis or autonomous vehicles from being sufficiently trustworthy
for wide deployment. The massive proliferation of AI across society will require radically new
ideas to yield technology that will not sacrifice our productivity, our quality of life, or our values.
