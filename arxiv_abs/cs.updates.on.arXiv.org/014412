Training a neural network with a large labeled dataset is still a dominant paradigm in computational
histopathology. However, obtaining such exhaustive manual annotations is often expensive, laborious,
and prone to inter and Intra-observer variability. While recent self-supervised and semi-supervised
methods can alleviate this need by learn-ing unsupervised feature representations, they still
struggle to generalize well to downstream tasks when the number of labeled instances is small. In
this work, we overcome this challenge by leveraging both task-agnostic and task-specific unlabeled
data based on two novel strategies: i) a self-supervised pretext task that harnesses the underlying
multi-resolution contextual cues in histology whole-slide images to learn a powerful supervisory
signal for unsupervised representation learning; ii) a new teacher-student semi-supervised
consistency paradigm that learns to effectively transfer the pretrained representations to downstream
tasks based on prediction consistency with the task-specific un-labeled data. We carry out extensive
validation experiments on three histopathology benchmark datasets across two classification
and one regression-based tasks, i.e., tumor metastasis detection, tissue type classification,
and tumor cellularity quantification. Under limited-label data, the proposed method yields tangible
improvements, which is close or even outperforming other state-of-the-art self-supervised and
supervised baselines. Furthermore, we empirically show that the idea of bootstrapping the self-supervised
pretrained features is an effective way to improve the task-specific semi-supervised learning
on standard benchmarks. Code and pretrained models will be made available at: https://github.com/srinidhiPY/SSL_CR_Histo
