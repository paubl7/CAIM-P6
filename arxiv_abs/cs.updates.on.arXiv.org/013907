Commonsense knowledge is essential for many AI applications, including those in natural language
processing, visual processing, and planning. Consequently, many sources that include commonsense
knowledge have been designed and constructed over the past decades. Recently, the focus has been
on large text-based sources, which facilitate easier integration with neural (language) models
and application on textual tasks, typically at the expense of the semantics of the sources. Such
practice prevents the harmonization of these sources, understanding their coverage and gaps,
and may hinder the semantic alignment of their knowledge with downstream tasks. Efforts to consolidate
commonsense knowledge have yielded partial success, but provide no clear path towards a comprehensive
consolidation of existing commonsense knowledge. The ambition of this paper is to organize these
sources around a common set of dimensions of commonsense knowledge. For this purpose, we survey
a wide range of popular commonsense sources with a special focus on their relations. We consolidate
these relations into 13 knowledge dimensions, each abstracting over more specific relations found
in sources. This consolidation allows us to unify the separate sources and to compute indications
of their coverage, overlap, and gaps with respect to the knowledge dimensions. Moreover, we analyze
the impact of each dimension on downstream reasoning tasks that require commonsense knowledge,
observing that the temporal and desire/goal dimensions are very beneficial for reasoning on current
downstream tasks, while distinctness and lexical knowledge have little impact. These results
reveal focus towards some dimensions in current evaluation, and potential neglect of others. 