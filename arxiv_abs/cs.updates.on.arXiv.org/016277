Analogy-making is at the core of human intelligence and creativity with applications to such diverse
tasks as commonsense reasoning, learning, language acquisition, and story telling. This paper
contributes to the foundations of artificial general intelligence by introducing from first principles
an abstract algebraic framework of analogical proportions of the form `$a$ is to $b$ what $c$ is to
$d$' in the general setting of universal algebra. This enables us to compare mathematical objects
possibly across different domains in a uniform way which is crucial for AI-systems. The main idea
is to define solutions to analogical equations in terms of maximal sets of algebraic justifications,
which amounts to deriving abstract terms of concrete elements from a `known' source domain which
can then be instantiated in an `unknown' target domain to obtain analogous elements. It turns out
that our notion of analogical proportions has appealing mathematical properties. For example,
we show that analogical proportions preserve functional dependencies across different domains,
which is desirable. We study Lepage's axioms of analogical proportions and argue why we disagree
with his symmetry, central permutation, strong reflexivity, and strong determinism axioms. We
compare our framework with two prominent and recently introduced frameworks of analogical proportions
from the literature in the concrete domains of sets and numbers, and we show that in each case we either
disagree with the notion from the literature justified by some plausible counter-example or we
can show that our model yields strictly more reasonable solutions. This provides evidence for its
applicability. In a broader sense, this paper is a first step towards a theory of analogical reasoning
and learning systems with potential applications to fundamental AI-problems like commonsense
reasoning and computational learning and creativity. 