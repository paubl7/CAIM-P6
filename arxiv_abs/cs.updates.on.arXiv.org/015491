Robotics in Australia have a long history of conforming with safety standards and risk managed practices.
This chapter articulates the current state of trust and safety in robotics including society's
expectations, safety management systems and system safety as well as emerging issues and methods
for ensuring safety in increasingly autonomous robotics. The future of trust and safety will combine
standards with iterative, adaptive and responsive regulatory and assurance methods for diverse
applications of robotics, autonomous systems and artificial intelligence (RAS-AI). Robotics
will need novel technical and social approaches to achieve assurance, particularly for game-changing
innovations. The ability for users to easily update algorithms and software, which alters the performance
of a system, implies that traditional machine assurance performed prior to deployment or sale,
will no longer be viable. Moreover, the high frequency of updates implies that traditional certification
that requires substantial time will no longer be practical. To alleviate these difficulties, automation
of assurance will likely be needed; something like 'ASsurance-as-a-Service' (ASaaS), where APIs
constantly ping RAS-AI to ensure abidance with various rules, frameworks and behavioural expectations.
There are exceptions to this, such as in contested or communications denied environments, or in
underground or undersea mining; and these systems need their own risk assessments and limitations
imposed. Indeed, self-monitors are already operating within some systems. To ensure safe operations
of future robotics systems, Australia needs to invest in RAS-AI assurance research, stakeholder
engagement and continued development and refinement of robust frameworks, methods, guidelines
and policy in order to educate and prepare its technology developers, certifiers, and general population.
