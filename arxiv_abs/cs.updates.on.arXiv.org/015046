The emergence of digital technologies such as smartphones in healthcare applications have demonstrated
the possibility of developing rich, continuous, and objective measures of multiple sclerosis
(MS) disability that can be administered remotely and out-of-clinic. In this work, deep convolutional
neural networks (DCNN) applied to smartphone inertial sensor data were shown to better distinguish
healthy from MS participant ambulation, compared to standard Support Vector Machine (SVM) feature-based
methodologies. To overcome the typical limitations associated with remotely generated health
data, such as low subject numbers, sparsity, and heterogeneous data, a transfer learning (TL) model
from similar large open-source datasets was proposed. Our TL framework utilised the ambulatory
information learned on Human Activity Recognition (HAR) tasks collected from similar smartphone-based
sensor data. A lack of transparency of "black-box" deep networks remains one of the largest stumbling
blocks to the wider acceptance of deep learning for clinical applications. Ensuing work therefore
aimed to visualise DCNN decisions attributed by relevance heatmaps using Layer-Wise Relevance
Propagation (LRP). Through the LRP framework, the patterns captured from smartphone-based inertial
sensor data that were reflective of those who are healthy versus persons with MS (PwMS) could begin
to be established and understood. Interpretations suggested that cadence-based measures, gait
speed, and ambulation-related signal perturbations were distinct characteristics that distinguished
MS disability from healthy participants. Robust and interpretable outcomes, generated from high-frequency
out-of-clinic assessments, could greatly augment the current in-clinic assessment picture for
PwMS, to inform better disease management techniques, and enable the development of better therapeutic
interventions. 