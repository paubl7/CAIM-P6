The past decade has witnessed a groundbreaking rise of machine learning for human language analysis,
with current methods capable of automatically accurately recovering various aspects of syntax
and semantics - including sentence structure and grounded word meaning - from large data collections.
Recent research showed the promise of such tools for analyzing acoustic communication in nonhuman
species. We posit that machine learning will be the cornerstone of future collection, processing,
and analysis of multimodal streams of data in animal communication studies, including bioacoustic,
behavioral, biological, and environmental data. Cetaceans are unique non-human model species
as they possess sophisticated acoustic communications, but utilize a very different encoding
system that evolved in an aquatic rather than terrestrial medium. Sperm whales, in particular,
with their highly-developed neuroanatomical features, cognitive abilities, social structures,
and discrete click-based encoding make for an excellent starting point for advanced machine learning
tools that can be applied to other animals in the future. This paper details a roadmap toward this
goal based on currently existing technology and multidisciplinary scientific community effort.
We outline the key elements required for the collection and processing of massive bioacoustic data
of sperm whales, detecting their basic communication units and language-like higher-level structures,
and validating these models through interactive playback experiments. The technological capabilities
developed by such an undertaking are likely to yield cross-applications and advancements in broader
communities investigating non-human communication and animal behavioral research. 