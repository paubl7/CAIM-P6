Motion sensors embedded in wearable and mobile devices allow for dynamic selection of sensor streams
and sampling rates, enabling useful applications, e.g. for power management or control of data
sharing. While deep neural networks (DNNs) achieve competitive accuracy in sensor data classification,
current DNN architectures only process data coming from a fixed set of sensors with a fixed sampling
rate, and changes in the dimensions of their inputs cause considerable accuracy loss, unnecessary
computations, or failure in operation. To address this problem, we introduce a dimension-adaptive
pooling (DAP) layer that makes DNNs flexible and more robust to changes in sampling rate and in sensor
availability. DAP operates on convolutional filter maps of variable dimensions and produces an
input of fixed dimensions suitable for feedforward and recurrent layers. Further, we propose a
dimension-adaptive training (DAT) procedure for enabling DNNs that use DAP to better generalize
over the set of feasible data dimensions at inference time. DAT comprises the random selection of
dimensions during the forward passes and optimization with accumulated gradients of several backward
passes. Combining DAP and DAT, we show how to transform existing non-adaptive DNNs into a Dimension-Adaptive
Neural Architecture (DANA), while keeping the same number of parameters. Compared to the existing
approaches, DANA provides better average classification accuracy over the range of possible data
dimensions, and it does not need up-sampling or imputation, thus reduces unnecessary computations
at inference time. Experimental results, on four benchmark real-world datasets of human activity
recognition as well as three synthetic datasets, show that DANA prevents significant losses in
classification accuracy of the state-of-the-art DNNs and, compared to baselines, it better captures
correlated patterns in sensor data. 