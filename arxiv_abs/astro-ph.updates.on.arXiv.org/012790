Twenty years ago, the mismatch between the observed number of Milky Way satellite galaxies and the
predicted number of cold dark matter subhalos was dubbed the "missing satellites problem". Although
mostly framed since in terms of satellite counts in luminosity space, the missing satellites problem
was originally posed in velocity space. The stellar velocity dispersion function encodes information
about the density profile of satellites as well as their abundance. We compare the completeness-corrected
MW satellite velocity function down to its ultrafaint dwarfs (L > 340 L$_\odot$) against well-motivated,
semi-empirical predictions based on galaxy-halo scaling relations. For our most conservative
completeness correction, we find good agreement with a simple CDM model in which massive, classical
satellites (M$_{\rm vir} \gtrsim 10^9~$M$_\odot$) have baryon-driven cores, while low-mass,
ultrafaint satellites (M$_{\rm vir} \lesssim 10^9~$M$_\odot$) inhabit cuspy halos that are not
strongly tidally stripped. This bifurication is required to explain a non-power-law feature in
the velocity function at $\sigma_{\rm los}^* \approx 10$ km/s. Intriguingly, this feature could
point to a flattening of the stellar-mass--halo-mass relation. Tidal destruction of satellites
by the Milky Way's disk must be minimal, or the corrected velocity function exceeds any plausible
prediction -- a "too many satellites" problem. We rule out non-core-collapsing self-interacting
dark matter models with a constant cross section $\gtrsim$ 0.3 cm$^2$/g. Constraints on warm dark
matter are stronger than those based on the luminosity function on account of the velocity function's
additional sensitivity to the central densities of subhalos. Reducing uncertainties on stellar
kinematics and the amount of tidal stripping experienced by the faintest dwarfs is key to determining
the severity of the too many satellites problem. 