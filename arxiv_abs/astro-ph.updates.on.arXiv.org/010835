The unprecedented amount and the excellent quality of lensing data that the upcoming ground- and
space-based surveys will produce represent a great opportunity to shed light on the questions that
still remain unanswered concerning our universe and the validity of the standard $\Lambda$CDM
cosmological model. Therefore, it is important to develop new techniques that can exploit the huge
quantity of data that future observations will give us access to in the most effective way possible.
For this reason, we decided to investigate the development of a new method to treat weak lensing higher
order statistics, which are known to break degeneracy among cosmological parameters thanks to
their capability of probing the non-Gaussian properties of the shear field. In particular, the
proposed method directly applies to the observed quantity, i.e., the noisy galaxy ellipticity.
We produced simulated lensing maps with different sets of cosmological parameters and used them
to measure higher order moments, Minkowski functionals, Betti numbers, and other statistics related
to graph theory. This allowed us to construct datasets with different size, precision, and smoothing.
We then applied several machine learning algorithms to determine which method best predicts the
actual cosmological parameters associated with each simulation. The best model resulted to be
simple multidimensional linear regression. We used this model to compare the results coming from
the different datasets and found out that we can measure with good accuracy the majority of the parameters
that we considered. We also investigated the relation between each higher order estimator and the
different cosmological parameters for several signal-to-noise thresholds and redshifts bins.
Given the promising results, we consider this approach as a valuable resource, worth of further
development. 