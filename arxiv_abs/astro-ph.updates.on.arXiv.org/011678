The delay time distribution (DTD) of Type-Ia supernovae (SNe Ia) is important for understanding
chemical evolution, SN Ia progenitors, and SN Ia physics. Past estimates of the DTD in galaxy clusters
have been deduced from SN Ia rates measured in cluster samples observed at various redshifts, corresponding
to different time intervals after a presumed initial brief burst of star formation. A recent analysis
of a cluster sample at $z=1.13-1.75$ confirmed indications from previous studies of lower-redshift
clusters, that the DTD has a power-law form, ${\rm DTD}(t)=R_1 (t/{\rm Gyr})^\alpha$, with amplitude
$R_1$, at delay $t=1~\rm Gyr$, several times higher than measured in field-galaxy environments.
This implied that SNe Ia are somehow produced in larger numbers by the stellar populations in clusters.
This conclusion, however, could have been affected by the implicit assumption that the stars were
formed in a single brief starburst at high $z$. Here, we re-derive the DTD from the cluster SN Ia data,
but relax the single-burst assumption. Instead, we allow for a range of star-formation histories
and dust extinctions for each cluster. Via MCMC modeling, we simultaneously fit, using stellar
population synthesis models and DTD models, the integrated galaxy-light photometry in several
bands, and the SN Ia numbers discovered in each cluster. With these more-realistic assumptions,
we find a best-fit DTD with power-law index $\alpha=-1.09_{-0.12}^{+0.15}$, and amplitude $R_1=0.41_{-0.10}^{+0.12}\times
10^{-12}~{\rm yr}^{-1}{\rm M}_\odot^{-1}$. We confirm a cluster-environment DTD with a larger
amplitude than the field-galaxy DTD, by a factor $\sim2-3$ (at $3.8\sigma$). Cluster and field
DTDs have consistent slopes of $\alpha\approx-1.1$. 