The delay time distribution (DTD) of Type-Ia supernovae (SNe Ia) is the rate of SNe Ia, as a function
of time, that explode in a hypothetical stellar population of unit mass, formed in a brief burst at
time $t=0$, and is important for understanding chemical evolution, SN Ia progenitors, and SN Ia
physics. Past estimates of the DTD in galaxy clusters have been deduced from SN Ia rates measured
in cluster samples observed at various redshifts, corresponding to different time intervals after
a presumed initial brief burst of star formation. Recently, Friedmann and Maoz analysed a cluster
sample at $z=1.13-1.75$ and confirmed indications from previous studies of lower-redshift clusters,
that the DTD has a power-law form whose normalisation is at least several times higher than measured
in field-galaxy environments, implying that SNe Ia are produced in larger numbers by the stellar
populations in clusters. This conclusion, however, could have been affected by the implicit assumption
that the stars were formed in a single brief starburst at high $z$. Here, we re-derive the DTD from
the cluster SN Ia data, but now relax the single-burst assumption. Instead, we allow for a range of
star-formation histories and dust extinctions for each cluster. Via MCMC modeling, we simultaneously
fit, using stellar population synthesis models and DTD models, the integrated galaxy-light photometry
in several bands and the SN Ia numbers discovered in each cluster. With these more-realistic assumptions,
we find a best-fit DTD with power-law index $\alpha=-1.09_{-0.12}^{+0.15}$, and amplitude, at
delay $t=1~\rm Gyr$, $R_1=0.41_{-0.10}^{+0.12}\times 10^{-12}~{\rm yr}^{-1}{\rm M}_\odot^{-1}$.
The derived cluster-environment DTD remains higher (at $3.8\sigma$ significance) than the field-galaxy
DTD, by a factor $\sim 2-3$. Cluster and field DTDs both have consistent slopes of $\alpha\approx
-1.1$. 