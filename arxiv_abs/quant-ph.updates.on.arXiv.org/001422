Computational physics is an important tool for analysing, verifying, and -- at times -- replacing
physical experiments. Nevertheless, simulating quantum systems and analysing quantum data has
so far resisted an efficient classical treatment in full generality. While programmable quantum
systems have been developed to address this challenge, the resources required for classically
intractable problems still lie beyond our reach. In this work, we consider a new target for quantum
simulation algorithms; analysing the data arising from physics experiments -- specifically,
muon spectroscopy experiments. These experiments can be used to probe the quantum interactions
present in condensed matter systems. However, fully analysing their results can require classical
computational resources scaling exponentially with the simulated system size, which can limit
our understanding of the studied system. We show that this task may be a natural fit for the coming
generations of quantum computers. We use classical emulations of our quantum algorithm on systems
of up to 29 qubits to analyse real experimental data, and to estimate both the near-term and error
corrected resources required for our proposal. We find that our algorithm exhibits good noise resilience,
stemming from our desire to extract global parameters from a fitted curve, rather than targeting
any individual data point. In some respects, our resource estimates go further than some prior work
in quantum simulation, by estimating the resources required to solve a complete task, rather than
just to run a given circuit. Taking the overhead of observable measurement and calculating multiple
datapoints into account, we find that significant challenges still remain if our algorithm is to
become practical for analysing muon spectroscopy data. 