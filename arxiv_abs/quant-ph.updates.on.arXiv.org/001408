We provide conceptual and mathematical foundations for near-term quantum natural language processing
(QNLP), and do so in quantum computer scientist friendly terms. We opted for an expository presentation
style, and provide references for supporting empirical evidence and formal statements concerning
mathematical generality. We recall how the quantum model for natural language that we employ canonically
combines linguistic meanings with rich linguistic structure, most notably grammar. In particular,
the fact that it takes a quantum-like model to combine meaning and structure, establishes QNLP as
quantum-native, on par with simulation of quantum systems. Moreover, the now leading Noisy Intermediate-Scale
Quantum (NISQ) paradigm for encoding classical data on quantum hardware, variational quantum
circuits, makes NISQ exceptionally QNLP-friendly: linguistic structure can be encoded as a free
lunch, in contrast to the apparently exponentially expensive classical encoding of grammar. Quantum
speed-up for QNLP tasks has already been established in previous work with Will Zeng. Here we provide
a broader range of tasks which all enjoy the same advantage. Diagrammatic reasoning is at the heart
of QNLP. Firstly, the quantum model interprets language as quantum processes via the diagrammatic
formalism of categorical quantum mechanics. Secondly, these diagrams are via ZX-calculus translated
into quantum circuits. Parameterisations of meanings then become the circuit variables to be learned.
Our encoding of linguistic structure within quantum circuits also embodies a novel approach for
establishing word-meanings that goes beyond the current standards in mainstream AI, by placing
linguistic structure at the heart of Wittgenstein's meaning-is-context. 