The term randomized benchmarking refers to a collection of protocols that in the past decade have
become the gold standard for characterizing quantum gates. These protocols aim at efficiently
estimating the quality of a set of quantum gates in a way that is resistant to state preparation and
measurement errors, and over the years many versions have been devised. In this work, we develop
a comprehensive framework of randomized benchmarking general enough to encompass virtually all
known protocols. Overcoming previous limitations on e.g. error models and gate sets, this framework
allows us to formulate realistic conditions under which we can rigorously guarantee that the output
of a randomized benchmarking experiment is well-described by a linear combination of matrix exponential
decays. We complement this with a detailed discussion of the fitting problem associated to randomized
benchmarking data. We discuss modern signal processing techniques and their guarantees in the
context of randomized benchmarking, give analytical sample complexity bounds and numerically
evaluate their performance and limitations. In order to reduce the resource demands of this fitting
problem, we moreover provide scalable post-processing techniques to isolate exponential decays,
significantly improving the practical feasibility of a large set of randomized benchmarking protocols.
These post-processing techniques generalize several previously proposed methods such as character
benchmarking and linear-cross entropy benchmarking. Finally we discuss, in full generality,
how and when randomized benchmarking decay rates can be used to infer quality measures like the average
fidelity. On the technical side, our work significantly extends the recently developed Fourier-theoretic
perspective on randomized benchmarking and combines it with the perturbation theory of invariant
subspaces and ideas from signal processing. 